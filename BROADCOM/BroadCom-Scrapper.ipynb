{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3c865c76-b966-4091-8618-8df066736939",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Broadcom Job Scraper\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter job title to search for (leave empty to get all jobs):  Design\n",
      "Maximum number of pages to scrape (default 10):  2\n",
      "Run in headless mode? (y/n, default: n):  y\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-17 22:39:19,961 - INFO - Starting Broadcom job scraper at 2025-03-17 22:39:19\n",
      "2025-03-17 22:39:19,966 - INFO - ====== WebDriver manager ======\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting job scraper...\n",
      "This may take several minutes depending on the number of jobs and pages.\n",
      "Progress will be logged to the console and a log file.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-17 22:39:20,324 - INFO - Get LATEST chromedriver version for google-chrome\n",
      "2025-03-17 22:39:20,387 - INFO - Get LATEST chromedriver version for google-chrome\n",
      "2025-03-17 22:39:20,525 - INFO - Driver [/Users/srikar/.wdm/drivers/chromedriver/mac64/134.0.6998.88/chromedriver-mac-arm64/chromedriver] found in cache\n",
      "2025-03-17 22:39:21,815 - INFO - Scraping jobs from Broadcom, searching for 'Design'\n",
      "2025-03-17 22:39:23,812 - INFO - Job listings found with selector: [data-automation-id='jobTitle']\n",
      "2025-03-17 22:39:23,818 - INFO - Starting to scroll to load all content...\n",
      "2025-03-17 22:39:27,330 - INFO - Scroll 1: Height 4605 → 4605, Jobs found: 20\n",
      "2025-03-17 22:39:30,790 - INFO - Scroll 2: Height 4605 → 4605, Jobs found: 20\n",
      "2025-03-17 22:39:30,790 - INFO - No change detected (1/3)\n",
      "2025-03-17 22:39:34,267 - INFO - Scroll 3: Height 4605 → 4605, Jobs found: 20\n",
      "2025-03-17 22:39:34,269 - INFO - No change detected (2/3)\n",
      "2025-03-17 22:39:37,757 - INFO - Scroll 4: Height 4605 → 4605, Jobs found: 20\n",
      "2025-03-17 22:39:37,757 - INFO - No change detected (3/3)\n",
      "2025-03-17 22:39:37,758 - INFO - No more content loading after multiple scrolls. Stopping scroll operation.\n",
      "2025-03-17 22:39:37,758 - INFO - Completed scrolling after 3 scrolls. Found approximately 20 job items.\n",
      "2025-03-17 22:39:38,178 - INFO - Starting pagination handling...\n",
      "2025-03-17 22:39:38,178 - INFO - Processing page 1\n",
      "2025-03-17 22:39:38,611 - INFO - Job listings found with selector: [data-automation-id='jobTitle']\n",
      "2025-03-17 22:39:38,616 - INFO - Found 20 job elements using selector: [data-automation-id='jobTitle']\n",
      "2025-03-17 22:39:39,130 - INFO - Added job: Design Verification Engineer at We are a global technology leader that designs, develops and supplies a broad range of semiconductor and infrastructure software solutions.\n",
      "2025-03-17 22:39:39,174 - INFO - Added job: Technical Support Engineer at We are a global technology leader that designs, develops and supplies a broad range of semiconductor and infrastructure software solutions.\n",
      "2025-03-17 22:39:39,217 - INFO - Added job: Software Engineer at We are a global technology leader that designs, develops and supplies a broad range of semiconductor and infrastructure software solutions.\n",
      "2025-03-17 22:39:39,260 - INFO - Added job: Software Engineer at We are a global technology leader that designs, develops and supplies a broad range of semiconductor and infrastructure software solutions.\n",
      "2025-03-17 22:39:39,303 - INFO - Added job: Build Infrastructure Developer at We are a global technology leader that designs, develops and supplies a broad range of semiconductor and infrastructure software solutions.\n",
      "2025-03-17 22:39:39,345 - INFO - Added job: ASIC Implementation Engineer at We are a global technology leader that designs, develops and supplies a broad range of semiconductor and infrastructure software solutions.\n",
      "2025-03-17 22:39:39,387 - INFO - Added job: IC Design and Verification Engineer at We are a global technology leader that designs, develops and supplies a broad range of semiconductor and infrastructure software solutions.\n",
      "2025-03-17 22:39:39,430 - INFO - Added job: ASIC Implementation Engineer at We are a global technology leader that designs, develops and supplies a broad range of semiconductor and infrastructure software solutions.\n",
      "2025-03-17 22:39:39,473 - INFO - Added job: ASIC Implementation Engineer at We are a global technology leader that designs, develops and supplies a broad range of semiconductor and infrastructure software solutions.\n",
      "2025-03-17 22:39:39,515 - INFO - Added job: ASIC Implementation Engineer at We are a global technology leader that designs, develops and supplies a broad range of semiconductor and infrastructure software solutions.\n",
      "2025-03-17 22:39:39,558 - INFO - Added job: R&D Softare Engineer at We are a global technology leader that designs, develops and supplies a broad range of semiconductor and infrastructure software solutions.\n",
      "2025-03-17 22:39:39,602 - INFO - Added job: Systems Supply Chain Analyst at We are a global technology leader that designs, develops and supplies a broad range of semiconductor and infrastructure software solutions.\n",
      "2025-03-17 22:39:39,647 - INFO - Added job: R&D Engineer Hardware at We are a global technology leader that designs, develops and supplies a broad range of semiconductor and infrastructure software solutions.\n",
      "2025-03-17 22:39:39,692 - INFO - Added job: Senior DevOps Platform Engineer at We are a global technology leader that designs, develops and supplies a broad range of semiconductor and infrastructure software solutions.\n",
      "2025-03-17 22:39:39,736 - INFO - Added job: R&D Engineer-2 at We are a global technology leader that designs, develops and supplies a broad range of semiconductor and infrastructure software solutions.\n",
      "2025-03-17 22:39:39,780 - INFO - Added job: Analog Mixed Signal Layout Designer at We are a global technology leader that designs, develops and supplies a broad range of semiconductor and infrastructure software solutions.\n",
      "2025-03-17 22:39:39,826 - INFO - Added job: Principal Engineer, Virtual Devices at We are a global technology leader that designs, develops and supplies a broad range of semiconductor and infrastructure software solutions.\n",
      "2025-03-17 22:39:39,877 - INFO - Added job: ESX Engineer at We are a global technology leader that designs, develops and supplies a broad range of semiconductor and infrastructure software solutions.\n",
      "2025-03-17 22:39:39,919 - INFO - Added job: Technical Support Engineer at We are a global technology leader that designs, develops and supplies a broad range of semiconductor and infrastructure software solutions.\n",
      "2025-03-17 22:39:39,961 - INFO - Added job: Technical Support Engineer at We are a global technology leader that designs, develops and supplies a broad range of semiconductor and infrastructure software solutions.\n",
      "2025-03-17 22:39:39,962 - INFO - Found 20 jobs on page 1\n",
      "2025-03-17 22:39:40,076 - INFO - Clicked next page button\n",
      "2025-03-17 22:39:45,094 - INFO - Job listings found with selector: [data-automation-id='jobTitle']\n",
      "2025-03-17 22:39:45,822 - INFO - Processing page 2\n",
      "2025-03-17 22:39:46,519 - INFO - Job listings found with selector: [data-automation-id='jobTitle']\n",
      "2025-03-17 22:39:46,524 - INFO - Found 20 job elements using selector: [data-automation-id='jobTitle']\n",
      "2025-03-17 22:39:47,289 - INFO - Added job: R & D Engineer Software 5 at We are a global technology leader that designs, develops and supplies a broad range of semiconductor and infrastructure software solutions.\n",
      "2025-03-17 22:39:47,332 - INFO - Added job: DFT Engineer at We are a global technology leader that designs, develops and supplies a broad range of semiconductor and infrastructure software solutions.\n",
      "2025-03-17 22:39:47,374 - INFO - Added job: DFT Engineer at We are a global technology leader that designs, develops and supplies a broad range of semiconductor and infrastructure software solutions.\n",
      "2025-03-17 22:39:47,418 - INFO - Added job: System Signal/Power Integrity Engineer at We are a global technology leader that designs, develops and supplies a broad range of semiconductor and infrastructure software solutions.\n",
      "2025-03-17 22:39:47,462 - INFO - Added job: Fab Test Engineer at We are a global technology leader that designs, develops and supplies a broad range of semiconductor and infrastructure software solutions.\n",
      "2025-03-17 22:39:47,515 - INFO - Added job: Senior Engineer - PNR/STA at We are a global technology leader that designs, develops and supplies a broad range of semiconductor and infrastructure software solutions.\n",
      "2025-03-17 22:39:47,557 - INFO - Added job: Memory Circuit Design Engineer at We are a global technology leader that designs, develops and supplies a broad range of semiconductor and infrastructure software solutions.\n",
      "2025-03-17 22:39:47,599 - INFO - Added job: Photolithography Equipment and Process Engineer at We are a global technology leader that designs, develops and supplies a broad range of semiconductor and infrastructure software solutions.\n",
      "2025-03-17 22:39:47,642 - INFO - Added job: Principal Engineer - IDS Engineer (C/C++) at We are a global technology leader that designs, develops and supplies a broad range of semiconductor and infrastructure software solutions.\n",
      "2025-03-17 22:39:47,684 - INFO - Added job: Staff SRAM Design Engineer at We are a global technology leader that designs, develops and supplies a broad range of semiconductor and infrastructure software solutions.\n",
      "2025-03-17 22:39:47,727 - INFO - Added job: Senior Engineer- PNR/STA at We are a global technology leader that designs, develops and supplies a broad range of semiconductor and infrastructure software solutions.\n",
      "2025-03-17 22:39:47,772 - INFO - Added job: Senior Engineer- PNR/STA at We are a global technology leader that designs, develops and supplies a broad range of semiconductor and infrastructure software solutions.\n",
      "2025-03-17 22:39:47,816 - INFO - Added job: Product Line Manager at We are a global technology leader that designs, develops and supplies a broad range of semiconductor and infrastructure software solutions.\n",
      "2025-03-17 22:39:47,860 - INFO - Added job: SOI RFIC Designer at We are a global technology leader that designs, develops and supplies a broad range of semiconductor and infrastructure software solutions.\n",
      "2025-03-17 22:39:47,904 - INFO - Added job: DFT Design Automation Engineer at We are a global technology leader that designs, develops and supplies a broad range of semiconductor and infrastructure software solutions.\n",
      "2025-03-17 22:39:47,950 - INFO - Added job: PCIe/CXL Product Applications Engineer at We are a global technology leader that designs, develops and supplies a broad range of semiconductor and infrastructure software solutions.\n",
      "2025-03-17 22:39:47,994 - INFO - Added job: LED Sales at We are a global technology leader that designs, develops and supplies a broad range of semiconductor and infrastructure software solutions.\n",
      "2025-03-17 22:39:48,035 - INFO - Added job: Technical Adoption Manager – Application Networking & Security at We are a global technology leader that designs, develops and supplies a broad range of semiconductor and infrastructure software solutions.\n",
      "2025-03-17 22:39:48,079 - INFO - Added job: Technical Adoption Manager – Application Networking & Security at We are a global technology leader that designs, develops and supplies a broad range of semiconductor and infrastructure software solutions.\n",
      "2025-03-17 22:39:48,123 - INFO - Added job: SCT Installation Technician at We are a global technology leader that designs, develops and supplies a broad range of semiconductor and infrastructure software solutions.\n",
      "2025-03-17 22:39:48,123 - INFO - Found 20 jobs on page 2\n",
      "2025-03-17 22:39:48,195 - INFO - Clicked next page button\n",
      "2025-03-17 22:39:53,210 - INFO - Job listings found with selector: [data-automation-id='jobTitle']\n",
      "2025-03-17 22:39:53,920 - INFO - Collected 40 total jobs after pagination\n",
      "2025-03-17 22:39:53,920 - INFO - Getting descriptions for 40 jobs (up to 200)\n",
      "2025-03-17 22:39:53,925 - INFO - Getting description for job 1/40: Design Verification Engineer\n",
      "2025-03-17 22:40:01,286 - INFO - Saved full-page screenshot to job_description_screenshots/job_1_Design_Verification_Engineer.png\n",
      "2025-03-17 22:40:07,822 - INFO - Getting description for job 2/40: Technical Support Engineer\n",
      "2025-03-17 22:40:15,528 - INFO - Saved full-page screenshot to job_description_screenshots/job_2_Technical_Support_Engineer.png\n",
      "2025-03-17 22:40:26,478 - INFO - Getting description for job 3/40: Software Engineer\n",
      "2025-03-17 22:40:34,052 - INFO - Saved full-page screenshot to job_description_screenshots/job_3_Software_Engineer.png\n",
      "2025-03-17 22:40:44,781 - INFO - Getting description for job 4/40: Software Engineer\n",
      "2025-03-17 22:40:52,399 - INFO - Saved full-page screenshot to job_description_screenshots/job_4_Software_Engineer.png\n",
      "2025-03-17 22:41:02,886 - INFO - Getting description for job 5/40: Build Infrastructure Developer\n",
      "2025-03-17 22:41:10,327 - INFO - Saved full-page screenshot to job_description_screenshots/job_5_Build_Infrastructure_Developer.png\n",
      "2025-03-17 22:41:20,409 - INFO - Getting description for job 6/40: ASIC Implementation Engineer\n",
      "2025-03-17 22:41:27,729 - INFO - Saved full-page screenshot to job_description_screenshots/job_6_ASIC_Implementation_Engineer.png\n",
      "2025-03-17 22:41:37,509 - INFO - Getting description for job 7/40: IC Design and Verification Engineer\n",
      "2025-03-17 22:41:44,742 - INFO - Saved full-page screenshot to job_description_screenshots/job_7_IC_Design_and_Verification_Engineer.png\n",
      "2025-03-17 22:41:54,316 - INFO - Getting description for job 8/40: ASIC Implementation Engineer\n",
      "2025-03-17 22:42:01,532 - INFO - Saved full-page screenshot to job_description_screenshots/job_8_ASIC_Implementation_Engineer.png\n",
      "2025-03-17 22:42:08,542 - INFO - Getting description for job 9/40: ASIC Implementation Engineer\n",
      "2025-03-17 22:42:15,791 - INFO - Saved full-page screenshot to job_description_screenshots/job_9_ASIC_Implementation_Engineer.png\n",
      "2025-03-17 22:42:22,626 - INFO - Getting description for job 10/40: ASIC Implementation Engineer\n",
      "2025-03-17 22:42:29,685 - INFO - Saved full-page screenshot to job_description_screenshots/job_10_ASIC_Implementation_Engineer.png\n",
      "2025-03-17 22:42:36,331 - INFO - Getting description for job 11/40: R&D Softare Engineer\n",
      "2025-03-17 22:42:43,415 - INFO - Saved full-page screenshot to job_description_screenshots/job_11_R&D_Softare_Engineer.png\n",
      "2025-03-17 22:42:49,839 - INFO - Getting description for job 12/40: Systems Supply Chain Analyst\n",
      "2025-03-17 22:42:57,021 - INFO - Saved full-page screenshot to job_description_screenshots/job_12_Systems_Supply_Chain_Analyst.png\n",
      "2025-03-17 22:43:03,929 - INFO - Getting description for job 13/40: R&D Engineer Hardware\n",
      "2025-03-17 22:43:11,114 - INFO - Saved full-page screenshot to job_description_screenshots/job_13_R&D_Engineer_Hardware.png\n",
      "2025-03-17 22:43:17,718 - INFO - Getting description for job 14/40: Senior DevOps Platform Engineer\n",
      "2025-03-17 22:43:24,760 - INFO - Saved full-page screenshot to job_description_screenshots/job_14_Senior_DevOps_Platform_Engineer.png\n",
      "2025-03-17 22:43:31,344 - INFO - Getting description for job 15/40: R&D Engineer-2\n",
      "2025-03-17 22:43:38,338 - INFO - Saved full-page screenshot to job_description_screenshots/job_15_R&D_Engineer-2.png\n",
      "2025-03-17 22:43:44,790 - INFO - Getting description for job 16/40: Analog Mixed Signal Layout Designer\n",
      "2025-03-17 22:43:51,779 - INFO - Saved full-page screenshot to job_description_screenshots/job_16_Analog_Mixed_Signal_Layout_Designer.png\n",
      "2025-03-17 22:43:58,030 - INFO - Getting description for job 17/40: Principal Engineer, Virtual Devices\n",
      "2025-03-17 22:44:05,096 - INFO - Saved full-page screenshot to job_description_screenshots/job_17_Principal_Engineer,_Virtual_Devices.png\n",
      "2025-03-17 22:44:11,539 - INFO - Getting description for job 18/40: ESX Engineer\n",
      "2025-03-17 22:44:18,779 - INFO - Saved full-page screenshot to job_description_screenshots/job_18_ESX_Engineer.png\n",
      "2025-03-17 22:44:25,631 - INFO - Getting description for job 19/40: Technical Support Engineer\n",
      "2025-03-17 22:44:33,083 - INFO - Saved full-page screenshot to job_description_screenshots/job_19_Technical_Support_Engineer.png\n",
      "2025-03-17 22:44:42,939 - INFO - Getting description for job 20/40: Technical Support Engineer\n",
      "2025-03-17 22:44:50,428 - INFO - Saved full-page screenshot to job_description_screenshots/job_20_Technical_Support_Engineer.png\n",
      "2025-03-17 22:45:00,566 - INFO - Getting description for job 21/40: R & D Engineer Software 5\n",
      "2025-03-17 22:45:08,260 - INFO - Saved full-page screenshot to job_description_screenshots/job_21_R_&_D_Engineer_Software_5.png\n",
      "2025-03-17 22:45:18,770 - INFO - Getting description for job 22/40: DFT Engineer\n",
      "2025-03-17 22:45:26,443 - INFO - Saved full-page screenshot to job_description_screenshots/job_22_DFT_Engineer.png\n",
      "2025-03-17 22:45:36,665 - INFO - Getting description for job 23/40: DFT Engineer\n",
      "2025-03-17 22:45:44,103 - INFO - Saved full-page screenshot to job_description_screenshots/job_23_DFT_Engineer.png\n",
      "2025-03-17 22:45:53,779 - INFO - Getting description for job 24/40: System Signal/Power Integrity Engineer\n",
      "2025-03-17 22:46:01,227 - INFO - Saved full-page screenshot to job_description_screenshots/job_24_System_SignalPower_Integrity_Engineer.png\n",
      "2025-03-17 22:46:11,269 - INFO - Getting description for job 25/40: Fab Test Engineer\n",
      "2025-03-17 22:46:19,288 - INFO - Saved full-page screenshot to job_description_screenshots/job_25_Fab_Test_Engineer.png\n",
      "2025-03-17 22:46:30,429 - INFO - Getting description for job 26/40: Senior Engineer - PNR/STA\n",
      "2025-03-17 22:46:38,021 - INFO - Saved full-page screenshot to job_description_screenshots/job_26_Senior_Engineer_-_PNRSTA.png\n",
      "2025-03-17 22:46:49,373 - INFO - Getting description for job 27/40: Memory Circuit Design Engineer\n",
      "2025-03-17 22:46:56,927 - INFO - Saved full-page screenshot to job_description_screenshots/job_27_Memory_Circuit_Design_Engineer.png\n",
      "2025-03-17 22:47:08,704 - INFO - Getting description for job 28/40: Photolithography Equipment and Process Engineer\n",
      "2025-03-17 22:47:16,410 - INFO - Saved full-page screenshot to job_description_screenshots/job_28_Photolithography_Equipment_and_Process_Engineer.png\n",
      "2025-03-17 22:47:27,069 - INFO - Getting description for job 29/40: Principal Engineer - IDS Engineer (C/C++)\n",
      "2025-03-17 22:47:34,692 - INFO - Saved full-page screenshot to job_description_screenshots/job_29_Principal_Engineer_-_IDS_Engineer_(CC++).png\n",
      "2025-03-17 22:47:45,125 - INFO - Getting description for job 30/40: Staff SRAM Design Engineer\n",
      "2025-03-17 22:47:52,448 - INFO - Saved full-page screenshot to job_description_screenshots/job_30_Staff_SRAM_Design_Engineer.png\n",
      "2025-03-17 22:48:03,192 - INFO - Getting description for job 31/40: Senior Engineer- PNR/STA\n",
      "2025-03-17 22:48:10,566 - INFO - Saved full-page screenshot to job_description_screenshots/job_31_Senior_Engineer-_PNRSTA.png\n",
      "2025-03-17 22:48:20,364 - INFO - Getting description for job 32/40: Senior Engineer- PNR/STA\n",
      "2025-03-17 22:48:27,556 - INFO - Saved full-page screenshot to job_description_screenshots/job_32_Senior_Engineer-_PNRSTA.png\n",
      "2025-03-17 22:48:34,733 - INFO - Getting description for job 33/40: Product Line Manager\n",
      "2025-03-17 22:48:41,877 - INFO - Saved full-page screenshot to job_description_screenshots/job_33_Product_Line_Manager.png\n",
      "2025-03-17 22:48:48,805 - INFO - Getting description for job 34/40: SOI RFIC Designer\n",
      "2025-03-17 22:48:55,951 - INFO - Saved full-page screenshot to job_description_screenshots/job_34_SOI_RFIC_Designer.png\n",
      "2025-03-17 22:49:02,680 - INFO - Getting description for job 35/40: DFT Design Automation Engineer\n",
      "2025-03-17 22:49:09,822 - INFO - Saved full-page screenshot to job_description_screenshots/job_35_DFT_Design_Automation_Engineer.png\n",
      "2025-03-17 22:49:16,352 - INFO - Getting description for job 36/40: PCIe/CXL Product Applications Engineer\n",
      "2025-03-17 22:49:23,367 - INFO - Saved full-page screenshot to job_description_screenshots/job_36_PCIeCXL_Product_Applications_Engineer.png\n",
      "2025-03-17 22:49:30,137 - INFO - Getting description for job 37/40: LED Sales\n",
      "2025-03-17 22:49:37,362 - INFO - Saved full-page screenshot to job_description_screenshots/job_37_LED_Sales.png\n",
      "2025-03-17 22:49:43,626 - INFO - Getting description for job 38/40: Technical Adoption Manager – Application Networking & Security\n",
      "2025-03-17 22:49:51,825 - INFO - Saved full-page screenshot to job_description_screenshots/job_38_Technical_Adoption_Manager_–_Application_Networking_&_Security.png\n",
      "2025-03-17 22:50:06,929 - INFO - Getting description for job 39/40: Technical Adoption Manager – Application Networking & Security\n",
      "2025-03-17 22:50:14,983 - INFO - Saved full-page screenshot to job_description_screenshots/job_39_Technical_Adoption_Manager_–_Application_Networking_&_Security.png\n",
      "2025-03-17 22:50:30,245 - INFO - Getting description for job 40/40: SCT Installation Technician\n",
      "2025-03-17 22:50:38,070 - INFO - Saved full-page screenshot to job_description_screenshots/job_40_SCT_Installation_Technician.png\n",
      "2025-03-17 22:50:55,520 - INFO - Completed fetching descriptions for 40 jobs\n",
      "2025-03-17 22:50:55,523 - INFO - Saving all 40 jobs found in search results\n",
      "2025-03-17 22:50:55,794 - INFO - Detailed jobs saved to 'broadcom_jobs_detailed_Design_20250317_225055.csv'\n",
      "2025-03-17 22:50:55,804 - INFO - Simplified jobs list saved to 'broadcom_jobs_simple_Design_20250317_225055.csv'\n",
      "2025-03-17 22:50:55,808 - INFO - Jobs filtered by keyword 'Design' saved to 'broadcom_jobs_filtered_Design_20250317_225055.csv'\n",
      "2025-03-17 22:50:55,809 - INFO - Found 7 jobs matching the keyword out of 40 total jobs\n",
      "2025-03-17 22:50:55,815 - INFO - Completed in 695.85 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "Broadcom Job Scraping Results:\n",
      "Total jobs found: 40\n",
      "Unique locations: 1\n",
      "Sample jobs:\n",
      "                            Title  \\\n",
      "0    Design Verification Engineer   \n",
      "1      Technical Support Engineer   \n",
      "2               Software Engineer   \n",
      "3               Software Engineer   \n",
      "4  Build Infrastructure Developer   \n",
      "\n",
      "                                            Location  \n",
      "0  We are a global technology leader that designs...  \n",
      "1  We are a global technology leader that designs...  \n",
      "2  We are a global technology leader that designs...  \n",
      "3  We are a global technology leader that designs...  \n",
      "4  We are a global technology leader that designs...  \n",
      "\n",
      "Top locations:\n",
      "Location\n",
      "We are a global technology leader that designs, develops and supplies a broad range of semiconductor and infrastructure software solutions.    40\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Results saved to:\n",
      "- broadcom_jobs_detailed_Design_20250317_225055.csv\n",
      "- broadcom_jobs_simple_Design_20250317_225055.csv\n",
      "- broadcom_jobs_filtered_Design_20250317_225055.csv\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.alert import Alert\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.common.exceptions import TimeoutException, NoSuchElementException, StaleElementReferenceException\n",
    "import pandas as pd\n",
    "import time\n",
    "import requests\n",
    "import logging\n",
    "import re\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO, \n",
    "                    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "                    handlers=[\n",
    "                        logging.FileHandler(f\"broadcom_job_scraper_{datetime.now().strftime('%Y%m%d_%H%M%S')}.log\"),\n",
    "                        logging.StreamHandler()\n",
    "                    ])\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Function to scroll and load all jobs with improved logic\n",
    "def scroll_to_load_all(driver, max_scrolls=30, wait_time=2):\n",
    "    \"\"\"\n",
    "    Scroll the page to load all content with a maximum number of scrolls\n",
    "    For Broadcom's Workday-based site, which loads content dynamically\n",
    "    \"\"\"\n",
    "    scrolls = 0\n",
    "    last_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "    last_job_count = 0\n",
    "    consecutive_no_change = 0\n",
    "    \n",
    "    logger.info(\"Starting to scroll to load all content...\")\n",
    "    \n",
    "    while scrolls < max_scrolls:\n",
    "        # Scroll down\n",
    "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "        time.sleep(wait_time)  # Wait time for content to load\n",
    "        \n",
    "        # Take screenshot for debugging\n",
    "        driver.save_screenshot(f\"screenshots/scroll_{scrolls+1}.png\")\n",
    "        \n",
    "        # Try to find the \"Load More\" or similar buttons and click them\n",
    "        try:\n",
    "            load_more_buttons = driver.find_elements(By.XPATH, \n",
    "                \"//button[contains(text(), 'Load More') or contains(text(), 'Show More') or contains(@aria-label, 'Load') or contains(@class, 'load-more')]\")\n",
    "            if load_more_buttons:\n",
    "                for button in load_more_buttons:\n",
    "                    if button.is_displayed() and button.is_enabled():\n",
    "                        driver.execute_script(\"arguments[0].click();\", button)\n",
    "                        logger.info(\"Clicked 'Load More' button\")\n",
    "                        time.sleep(wait_time + 1)  # Extra wait for new content\n",
    "        except Exception as e:\n",
    "            logger.info(f\"No 'Load More' button found or error clicking it: {e}\")\n",
    "        \n",
    "        # Check height and job count to determine if we've loaded all content\n",
    "        new_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "        \n",
    "        # Try different job card selectors to get an accurate count\n",
    "        job_selectors = [\n",
    "            \"[data-automation-id='jobTitle']\", \n",
    "            \".WGDC\", \n",
    "            \"[role='listitem']\",\n",
    "            \".css-19uc56f\",\n",
    "            \".css-1q6t3sv div[role='row']\"\n",
    "        ]\n",
    "        \n",
    "        current_job_count = 0\n",
    "        for selector in job_selectors:\n",
    "            count = len(driver.find_elements(By.CSS_SELECTOR, selector))\n",
    "            if count > current_job_count:\n",
    "                current_job_count = count\n",
    "        \n",
    "        logger.info(f\"Scroll {scrolls+1}: Height {last_height} → {new_height}, Jobs found: {current_job_count}\")\n",
    "        \n",
    "        # If no change in height and job count, we might have reached the end\n",
    "        if new_height == last_height and current_job_count == last_job_count:\n",
    "            consecutive_no_change += 1\n",
    "            logger.info(f\"No change detected ({consecutive_no_change}/3)\")\n",
    "            if consecutive_no_change >= 3:  # If no change for 3 consecutive scrolls\n",
    "                logger.info(\"No more content loading after multiple scrolls. Stopping scroll operation.\")\n",
    "                break\n",
    "        else:\n",
    "            consecutive_no_change = 0\n",
    "            \n",
    "        last_height = new_height\n",
    "        last_job_count = current_job_count\n",
    "        scrolls += 1\n",
    "    \n",
    "    logger.info(f\"Completed scrolling after {scrolls} scrolls. Found approximately {last_job_count} job items.\")\n",
    "    return last_job_count\n",
    "\n",
    "# Function to handle pagination for Broadcom Workday\n",
    "def handle_pagination(driver, max_pages=20):\n",
    "    \"\"\"\n",
    "    Handle pagination by clicking through all available pages\n",
    "    \"\"\"\n",
    "    page = 1\n",
    "    all_jobs = []\n",
    "    \n",
    "    logger.info(\"Starting pagination handling...\")\n",
    "    \n",
    "    while page <= max_pages:\n",
    "        logger.info(f\"Processing page {page}\")\n",
    "        \n",
    "        # Take screenshot for debugging\n",
    "        driver.save_screenshot(f\"screenshots/page_{page}.png\")\n",
    "        \n",
    "        # Wait for job listings to be visible \n",
    "        wait_for_job_listings(driver)\n",
    "        \n",
    "        # Extract current page's jobs\n",
    "        jobs_on_page = extract_job_listings_broadcom(driver)\n",
    "        all_jobs.extend(jobs_on_page)\n",
    "        logger.info(f\"Found {len(jobs_on_page)} jobs on page {page}\")\n",
    "        \n",
    "        # Look for next page button - try multiple selectors\n",
    "        next_selectors = [\n",
    "            \"[aria-label='next page']\", \n",
    "            \"[data-automation-id='paginationNextButton']\",\n",
    "            \"button[title='Next Page']\",\n",
    "            \"button.css-1ddxsuf\",\n",
    "            \"button.next-page\",\n",
    "            \"//button[contains(@class, 'page') and contains(@class, 'next')]\",\n",
    "            \"//button[contains(@aria-label, 'next')]\"\n",
    "        ]\n",
    "        \n",
    "        next_button = None\n",
    "        for selector in next_selectors:\n",
    "            try:\n",
    "                if selector.startswith(\"//\"):\n",
    "                    elements = driver.find_elements(By.XPATH, selector)\n",
    "                else:\n",
    "                    elements = driver.find_elements(By.CSS_SELECTOR, selector)\n",
    "                \n",
    "                for elem in elements:\n",
    "                    if elem.is_displayed() and not (elem.get_attribute(\"disabled\") or \"disabled\" in elem.get_attribute(\"class\") or \"inactive\" in elem.get_attribute(\"class\")):\n",
    "                        next_button = elem\n",
    "                        break\n",
    "                        \n",
    "                if next_button:\n",
    "                    break\n",
    "            except Exception:\n",
    "                continue\n",
    "        \n",
    "        if not next_button:\n",
    "            logger.info(\"No next page button found. Reached last page.\")\n",
    "            break\n",
    "            \n",
    "        # Check if button is disabled (end of pages)\n",
    "        if next_button.get_attribute(\"disabled\") or \"disabled\" in next_button.get_attribute(\"class\"):\n",
    "            logger.info(\"Reached last page - Next button is disabled\")\n",
    "            break\n",
    "            \n",
    "        # Click next page using JavaScript to avoid intercept issues\n",
    "        try:\n",
    "            driver.execute_script(\"arguments[0].click();\", next_button)\n",
    "            logger.info(\"Clicked next page button\")\n",
    "            time.sleep(5)  # Wait for page to load\n",
    "            page += 1\n",
    "            \n",
    "            # Wait for job listings to reload\n",
    "            wait_for_job_listings(driver)\n",
    "            \n",
    "            # Take screenshot after page change\n",
    "            driver.save_screenshot(f\"screenshots/page_{page}_loaded.png\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error clicking next page: {e}\")\n",
    "            # Try one more time with a different approach\n",
    "            try:\n",
    "                driver.execute_script(\"arguments[0].scrollIntoView(true);\", next_button)\n",
    "                time.sleep(1)\n",
    "                next_button.click()\n",
    "                logger.info(\"Clicked next page button using alternative method\")\n",
    "                time.sleep(5)\n",
    "                page += 1\n",
    "            except Exception as e2:\n",
    "                logger.error(f\"Still failed to click next page: {e2}\")\n",
    "                break\n",
    "            \n",
    "    return all_jobs\n",
    "\n",
    "# Helper function to wait for job listings to appear\n",
    "def wait_for_job_listings(driver, timeout=15):\n",
    "    \"\"\"Wait for job listings to appear on the page using multiple possible selectors\"\"\"\n",
    "    selectors = [\n",
    "        \"[data-automation-id='jobTitle']\",\n",
    "        \".WGDC\",\n",
    "        \"[role='listitem']\",\n",
    "        \".css-19uc56f\",\n",
    "        \".css-1q6t3sv div[role='row']\",\n",
    "        \"ul[role='list'] li\"\n",
    "    ]\n",
    "    \n",
    "    for selector in selectors:\n",
    "        try:\n",
    "            WebDriverWait(driver, timeout).until(\n",
    "                EC.presence_of_element_located((By.CSS_SELECTOR, selector))\n",
    "            )\n",
    "            logger.info(f\"Job listings found with selector: {selector}\")\n",
    "            return True\n",
    "        except TimeoutException:\n",
    "            continue\n",
    "    \n",
    "    logger.warning(\"Could not detect job listings with any known selector\")\n",
    "    return False\n",
    "\n",
    "# Extract job information from Broadcom page\n",
    "def extract_job_listings_broadcom(driver):\n",
    "    \"\"\"\n",
    "    Extract job listings from Broadcom Workday page\n",
    "    Handles different potential Workday UI structures\n",
    "    \"\"\"\n",
    "    jobs_data = []\n",
    "    \n",
    "    # Try different selectors for job elements \n",
    "    selectors = [\n",
    "        # Primary Workday selectors\n",
    "        {\"container\": \"[data-automation-id='jobTitle']\", \"type\": \"primary\"},\n",
    "        {\"container\": \"[data-automation-id='job-card']\", \"type\": \"primary\"},\n",
    "        {\"container\": \".css-1q6t3sv [role='row']\", \"type\": \"row\"},\n",
    "        {\"container\": \"ul[role='list'] > li\", \"type\": \"list\"}, \n",
    "        {\"container\": \".WGDC a[role='link']\", \"type\": \"link\"}\n",
    "    ]\n",
    "    \n",
    "    job_elements = []\n",
    "    used_selector = None\n",
    "    \n",
    "    # Try each selector to find job elements\n",
    "    for selector in selectors:\n",
    "        try:\n",
    "            elements = driver.find_elements(By.CSS_SELECTOR, selector[\"container\"])\n",
    "            if elements and len(elements) > 0:\n",
    "                job_elements = elements\n",
    "                used_selector = selector\n",
    "                logger.info(f\"Found {len(elements)} job elements using selector: {selector['container']}\")\n",
    "                \n",
    "                # Take a screenshot of the found elements (for debugging)\n",
    "                if len(elements) > 0:\n",
    "                    try:\n",
    "                        driver.execute_script(\"arguments[0].style.border='3px solid red'\", elements[0])\n",
    "                        driver.save_screenshot(\"screenshots/job_elements_found.png\")\n",
    "                        driver.execute_script(\"arguments[0].style.border=''\", elements[0])\n",
    "                    except:\n",
    "                        pass\n",
    "                break\n",
    "        except Exception as e:\n",
    "            logger.debug(f\"Selector {selector['container']} failed: {e}\")\n",
    "            continue\n",
    "    \n",
    "    if not job_elements:\n",
    "        logger.warning(\"Could not find job elements with any selector. Taking screenshot for debugging.\")\n",
    "        driver.save_screenshot(\"screenshots/no_job_elements.png\")\n",
    "        return jobs_data\n",
    "    \n",
    "    # Extract detailed information for each job based on the selector type\n",
    "    for index, job in enumerate(job_elements):\n",
    "        try:\n",
    "            # Different extraction logic based on which selector worked\n",
    "            if used_selector[\"type\"] == \"primary\":  # Standard Workday implementation\n",
    "                title_element = job if \"jobTitle\" in used_selector[\"container\"] else job.find_element(By.CSS_SELECTOR, \"[data-automation-id='jobTitle']\")\n",
    "                title = title_element.text.strip()\n",
    "                link = title_element.get_attribute(\"href\")\n",
    "                \n",
    "                # Try to find location near the job title element\n",
    "                location = \"Not specified\"\n",
    "                try:\n",
    "                    # Find parent card or container\n",
    "                    parent_card = None\n",
    "                    try:\n",
    "                        parent_card = title_element.find_element(By.XPATH, \"ancestor::div[contains(@class, 'css-') and @data-automation-id]\")\n",
    "                    except:\n",
    "                        parent_card = title_element.find_element(By.XPATH, \"./ancestor::*[3]\")  # Go up a few levels\n",
    "                    \n",
    "                    # Try multiple location selectors\n",
    "                    location_selectors = [\n",
    "                        \"[data-automation-id='location']\", \n",
    "                        \"[data-automation-id='locationLabel']\",\n",
    "                        \".css-1wzygq\",\n",
    "                        \".css-129m7dg\",\n",
    "                        \"//span[contains(text(), ',')]\",\n",
    "                        \"//div[contains(text(), ',')]\"\n",
    "                    ]\n",
    "                    \n",
    "                    for loc_selector in location_selectors:\n",
    "                        try:\n",
    "                            if loc_selector.startswith(\"//\"):\n",
    "                                location_elem = parent_card.find_element(By.XPATH, loc_selector)\n",
    "                            else:\n",
    "                                location_elem = parent_card.find_element(By.CSS_SELECTOR, loc_selector)\n",
    "                                \n",
    "                            if location_elem:\n",
    "                                location = location_elem.text.strip()\n",
    "                                if location and (\",\" in location or \"Remote\" in location):\n",
    "                                    break\n",
    "                        except:\n",
    "                            continue\n",
    "                except Exception as e:\n",
    "                    logger.debug(f\"Could not find location with primary selectors: {e}\")\n",
    "                    # Fallback: look for any element that mentions location\n",
    "                    try:\n",
    "                        # Look for elements after the title with location formatting \n",
    "                        location_candidates = driver.find_elements(By.XPATH, \n",
    "                            f\"//div[contains(text(), '{title}')]/following::div[contains(text(), ',') or contains(text(), 'Remote')]\")\n",
    "                        if location_candidates:\n",
    "                            location = location_candidates[0].text.strip()\n",
    "                    except:\n",
    "                        pass\n",
    "                \n",
    "            elif used_selector[\"type\"] in [\"row\", \"list\", \"link\"]:  # Generic extraction for other selectors\n",
    "                # Find title element\n",
    "                title_elem = None\n",
    "                title_selectors = [\"a\", \"h3\", \"[title]\", \"[aria-label]\", \"span.css-srrtrq\"]\n",
    "                \n",
    "                for t_selector in title_selectors:\n",
    "                    try:\n",
    "                        title_candidates = job.find_elements(By.CSS_SELECTOR, t_selector)\n",
    "                        for elem in title_candidates:\n",
    "                            text = elem.text.strip() or elem.get_attribute(\"title\") or elem.get_attribute(\"aria-label\")\n",
    "                            if text and len(text) > 3:  # Ensure it's substantial text\n",
    "                                title_elem = elem\n",
    "                                break\n",
    "                        if title_elem:\n",
    "                            break\n",
    "                    except:\n",
    "                        continue\n",
    "                        \n",
    "                if not title_elem:\n",
    "                    logger.debug(f\"Could not find title for job {index+1}\")\n",
    "                    continue\n",
    "                    \n",
    "                title = title_elem.text.strip() or title_elem.get_attribute(\"title\") or title_elem.get_attribute(\"aria-label\")\n",
    "                link = title_elem.get_attribute(\"href\")\n",
    "                \n",
    "                if not link:\n",
    "                    # Try to find a parent or sibling with a link\n",
    "                    link_containers = job.find_elements(By.CSS_SELECTOR, \"a\")\n",
    "                    if link_containers:\n",
    "                        link = link_containers[0].get_attribute(\"href\")\n",
    "                \n",
    "                # Try to find location\n",
    "                location = \"Not specified\"\n",
    "                try:\n",
    "                    # Look for location in various ways\n",
    "                    location_patterns = [\n",
    "                        \".//span[contains(text(), ',')]\",\n",
    "                        \".//div[contains(text(), ',')]\",\n",
    "                        \".//div[contains(text(), 'Location')]//following-sibling::div\",\n",
    "                        \".//span[contains(text(), 'Remote')]\",\n",
    "                        \".//div[contains(@class, 'location')]\"\n",
    "                    ]\n",
    "                    \n",
    "                    for pattern in location_patterns:\n",
    "                        location_elems = job.find_elements(By.XPATH, pattern)\n",
    "                        if location_elems:\n",
    "                            location = location_elems[0].text.strip()\n",
    "                            if location and len(location) > 2:  # Ensure it's not empty\n",
    "                                break\n",
    "                except Exception as e:\n",
    "                    logger.debug(f\"Could not find location with alternative selectors: {e}\")\n",
    "            \n",
    "            # Add the extracted job if we have at least a title and link\n",
    "            if title and title.strip() and link and link.strip():\n",
    "                # Check for duplicate before adding\n",
    "                is_duplicate = False\n",
    "                for existing_job in jobs_data:\n",
    "                    if existing_job[\"Title\"] == title and existing_job[\"Link\"] == link:\n",
    "                        is_duplicate = True\n",
    "                        break\n",
    "                \n",
    "                if not is_duplicate:\n",
    "                    jobs_data.append({\n",
    "                        \"Title\": title,\n",
    "                        \"Location\": location,\n",
    "                        \"Link\": link,\n",
    "                        \"Description\": \"\",  # We'll get descriptions in a separate step\n",
    "                        \"Company\": \"Broadcom\"\n",
    "                    })\n",
    "                    logger.info(f\"Added job: {title} at {location}\")\n",
    "            \n",
    "        except (StaleElementReferenceException, Exception) as e:\n",
    "            logger.error(f\"Error extracting job details for job {index+1}: {e}\")\n",
    "            continue\n",
    "    \n",
    "    return jobs_data\n",
    "\n",
    "# Improved function to get job descriptions with full page screenshots saved in a separate folder\n",
    "def get_job_descriptions(driver, jobs_data, max_descriptions=100):\n",
    "    \"\"\"\n",
    "    Get job descriptions for a batch of jobs by visiting their individual pages.\n",
    "    Save full page screenshots of each job description in a separate folder.\n",
    "    \"\"\"\n",
    "    logger.info(f\"Getting descriptions for {len(jobs_data)} jobs (up to {max_descriptions})\")\n",
    "    \n",
    "    # Create a dedicated folder for job description screenshots\n",
    "    job_desc_folder = 'job_description_screenshots'\n",
    "    os.makedirs(job_desc_folder, exist_ok=True)\n",
    "    \n",
    "    # Store current URL to return to afterward\n",
    "    original_url = driver.current_url\n",
    "    original_window = driver.current_window_handle\n",
    "    \n",
    "    # Process up to max_descriptions\n",
    "    for i, job in enumerate(jobs_data[:max_descriptions]):\n",
    "        if not job.get(\"Link\"):\n",
    "            continue\n",
    "            \n",
    "        logger.info(f\"Getting description for job {i+1}/{min(len(jobs_data), max_descriptions)}: {job['Title']}\")\n",
    "        \n",
    "        # Create a clean filename from the job title\n",
    "        clean_title = re.sub(r'[\\\\/*?:\"<>|]', \"\", job['Title'])\n",
    "        clean_title = re.sub(r'\\s+', \"_\", clean_title)\n",
    "        clean_title = clean_title[:100] if len(clean_title) > 100 else clean_title\n",
    "        \n",
    "        # Create a new tab for each job\n",
    "        try:\n",
    "            # Open new tab\n",
    "            driver.execute_script(\"window.open('about:blank', '_blank');\")\n",
    "            driver.switch_to.window(driver.window_handles[-1])\n",
    "            \n",
    "            # Navigate to job details page\n",
    "            driver.get(job[\"Link\"])\n",
    "            time.sleep(5)  # Wait for page to load\n",
    "            \n",
    "            # Take a full page screenshot\n",
    "            # First, get the height of the entire page\n",
    "            total_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "            \n",
    "            # Set window size to capture entire page\n",
    "            driver.set_window_size(1920, total_height)\n",
    "            \n",
    "            # Take screenshot and save in the dedicated folder\n",
    "            screenshot_file = f\"{job_desc_folder}/job_{i+1}_{clean_title}.png\"\n",
    "            driver.save_screenshot(screenshot_file)\n",
    "            logger.info(f\"Saved full-page screenshot to {screenshot_file}\")\n",
    "            \n",
    "            # For long pages, also capture screenshots of each section\n",
    "            current_height = 0\n",
    "            viewport_height = 1080\n",
    "            section = 1\n",
    "            \n",
    "            while current_height < total_height:\n",
    "                driver.execute_script(f\"window.scrollTo(0, {current_height});\")\n",
    "                time.sleep(0.5)\n",
    "                section_screenshot = f\"{job_desc_folder}/job_{i+1}_{clean_title}_section_{section}.png\"\n",
    "                driver.save_screenshot(section_screenshot)\n",
    "                current_height += viewport_height\n",
    "                section += 1\n",
    "                \n",
    "            # Reset scroll position\n",
    "            driver.execute_script(\"window.scrollTo(0, 0);\")\n",
    "            \n",
    "            # Extract description using multiple potential selectors\n",
    "            description_selectors = [\n",
    "                \"[data-automation-id='job-description']\",\n",
    "                \".job-description\",\n",
    "                \"#job-description\",\n",
    "                \"[role='main']\",\n",
    "                \"article\",\n",
    "                \"[data-automation-id='jobPosting']\",\n",
    "                \".css-vh281m\",\n",
    "                \".css-1prfaxn\"\n",
    "            ]\n",
    "            \n",
    "            description = \"\"\n",
    "            for selector in description_selectors:\n",
    "                try:\n",
    "                    desc_elements = driver.find_elements(By.CSS_SELECTOR, selector)\n",
    "                    if desc_elements:\n",
    "                        description = desc_elements[0].text.strip()\n",
    "                        if description:\n",
    "                            logger.info(f\"Got description for '{job['Title']}' ({len(description)} chars)\")\n",
    "                            break\n",
    "                except Exception as e:\n",
    "                    logger.debug(f\"Selector {selector} failed: {e}\")\n",
    "            \n",
    "            # Update the job with the description\n",
    "            if description:\n",
    "                job[\"Description\"] = description\n",
    "            \n",
    "            # Close tab\n",
    "            driver.close()\n",
    "            driver.switch_to.window(original_window)\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error getting description for {job['Title']}: {e}\")\n",
    "            # Make sure we're back to the original window\n",
    "            try:\n",
    "                driver.close()\n",
    "                driver.switch_to.window(original_window)\n",
    "            except:\n",
    "                pass\n",
    "    \n",
    "    # Return to original page\n",
    "    try:\n",
    "        driver.get(original_url)\n",
    "        time.sleep(3)\n",
    "    except:\n",
    "        pass\n",
    "        \n",
    "    logger.info(f\"Completed fetching descriptions for {min(len(jobs_data), max_descriptions)} jobs\")\n",
    "    return jobs_data\n",
    "\n",
    "# Function to handle different types of popups\n",
    "def handle_popups(driver):\n",
    "    try:\n",
    "        # Common buttons for accepting cookies, terms, etc.\n",
    "        popup_selectors = [\n",
    "            \"//button[contains(text(), 'Accept')]\", \n",
    "            \"//button[contains(text(), 'I agree')]\",\n",
    "            \"//button[contains(@id, 'accept')]\",\n",
    "            \"//button[contains(@class, 'accept')]\",\n",
    "            \"//button[contains(text(), 'Continue')]\",\n",
    "            \"//button[contains(text(), 'Got it')]\",\n",
    "            \"//button[contains(text(), 'Close')]\",\n",
    "            \"//button[@aria-label='Close']\",\n",
    "            \"//div[contains(@class, 'cookie')]//button\",\n",
    "            \"//div[contains(@id, 'consent')]//button\"\n",
    "        ]\n",
    "        \n",
    "        for xpath in popup_selectors:\n",
    "            try:\n",
    "                buttons = driver.find_elements(By.XPATH, xpath)\n",
    "                for button in buttons:\n",
    "                    if button.is_displayed():\n",
    "                        button.click()\n",
    "                        logger.info(f\"Clicked popup/cookie button with xpath: {xpath}\")\n",
    "                        time.sleep(1)\n",
    "            except Exception:\n",
    "                continue\n",
    "                \n",
    "        # Handle alerts\n",
    "        try:\n",
    "            alert = Alert(driver)\n",
    "            alert.accept()\n",
    "            logger.info(\"Accepted alert popup\")\n",
    "        except:\n",
    "            pass\n",
    "            \n",
    "    except Exception as e:\n",
    "        logger.warning(f\"Error handling popups: {e}\")\n",
    "\n",
    "# Function to validate URL\n",
    "def is_valid_link(url):\n",
    "    if not url or not isinstance(url, str) or not url.startswith(\"http\"):\n",
    "        return False\n",
    "        \n",
    "    # For Broadcom Workday links, we'll assume they're valid without checking\n",
    "    if \"broadcom.wd1.myworkdayjobs.com\" in url:\n",
    "        return True\n",
    "        \n",
    "    try:\n",
    "        response = requests.head(url, timeout=5, allow_redirects=True)\n",
    "        return response.status_code < 400  # Accept any non-error status\n",
    "    except requests.RequestException:\n",
    "        logger.warning(f\"Invalid link: {url}\")\n",
    "        return False\n",
    "\n",
    "# Main Broadcom job scraper function\n",
    "def scrape_broadcom_jobs(search_keyword=\"\", max_pages=20, headless=False):\n",
    "    \"\"\"\n",
    "    Scrape Broadcom jobs with comprehensive approach including pagination.\n",
    "    The search_keyword is used only for searching on the website.\n",
    "    All found jobs will be saved regardless of keyword match.\n",
    "    \n",
    "    Parameters:\n",
    "    search_keyword (str): Keyword to search for (empty string for all jobs)\n",
    "    max_pages (int): Maximum number of pages to scrape\n",
    "    headless (bool): Whether to run in headless mode\n",
    "    \n",
    "    Returns:\n",
    "    list: List of all job dictionaries found\n",
    "    \"\"\"\n",
    "    options = webdriver.ChromeOptions()\n",
    "    \n",
    "    if headless:\n",
    "        options.add_argument('--headless')\n",
    "        \n",
    "    options.add_argument('--disable-gpu')\n",
    "    options.add_argument('--no-sandbox')\n",
    "    options.add_argument('--disable-dev-shm-usage')\n",
    "    options.add_argument('--window-size=1920,1080')\n",
    "    options.add_argument('--user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/98.0.4758.102 Safari/537.36')\n",
    "    \n",
    "    # Create directories for debugging\n",
    "    os.makedirs('screenshots', exist_ok=True)\n",
    "    \n",
    "    driver = None\n",
    "    jobs_data = []\n",
    "\n",
    "    try:\n",
    "        driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=options)\n",
    "        driver.set_page_load_timeout(30)\n",
    "        \n",
    "        # Construct search URL - Broadcom Workday URL\n",
    "        search_term = search_keyword.replace(\" \", \"%20\") if search_keyword else \"\"\n",
    "        if search_term:\n",
    "            base_url = f\"https://broadcom.wd1.myworkdayjobs.com/External_Career?q={search_term}\"\n",
    "        else:\n",
    "            base_url = \"https://broadcom.wd1.myworkdayjobs.com/External_Career\"\n",
    "\n",
    "        # Open the Broadcom careers page\n",
    "        logger.info(f\"Scraping jobs from Broadcom\" + (f\", searching for '{search_keyword}'\" if search_keyword else \"\"))\n",
    "        driver.get(base_url)\n",
    "        driver.save_screenshot(\"screenshots/broadcom_initial.png\")\n",
    "        \n",
    "        # Handle popups\n",
    "        handle_popups(driver)\n",
    "        \n",
    "        # Wait for results to load - trying different possible selectors\n",
    "        if not wait_for_job_listings(driver, timeout=20):\n",
    "            logger.warning(\"Could not detect job search results loading. Trying manual search...\")\n",
    "            \n",
    "            # Try to search directly by submitting a search form\n",
    "            try:\n",
    "                search_box = driver.find_element(By.CSS_SELECTOR, \"input[type='search'], input[placeholder*='Search']\")\n",
    "                search_box.clear()\n",
    "                search_box.send_keys(search_keyword)\n",
    "                search_box.send_keys(Keys.RETURN)\n",
    "                time.sleep(5)\n",
    "                logger.info(\"Tried manual search submission\")\n",
    "                driver.save_screenshot(\"screenshots/broadcom_manual_search.png\")\n",
    "                \n",
    "                # Wait again for results\n",
    "                wait_for_job_listings(driver, timeout=15)\n",
    "            except Exception as e:\n",
    "                logger.error(f\"Manual search also failed: {e}\")\n",
    "        \n",
    "        # Scroll to load all results on first page\n",
    "        job_count = scroll_to_load_all(driver, max_scrolls=20, wait_time=3)\n",
    "        driver.save_screenshot(\"screenshots/broadcom_after_scroll.png\")\n",
    "        \n",
    "        # Handle pagination and collect all jobs\n",
    "        all_jobs = handle_pagination(driver, max_pages=max_pages)\n",
    "        logger.info(f\"Collected {len(all_jobs)} total jobs after pagination\")\n",
    "        \n",
    "        # Get job descriptions for all collected jobs\n",
    "        jobs_with_descriptions = get_job_descriptions(driver, all_jobs, max_descriptions=200)\n",
    "        \n",
    "        # Save all jobs regardless of search keyword\n",
    "        jobs_data = jobs_with_descriptions\n",
    "        logger.info(f\"Saving all {len(jobs_data)} jobs found in search results\")\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error during scraping from Broadcom: {e}\")\n",
    "        if driver:\n",
    "            driver.save_screenshot(\"screenshots/broadcom_error.png\")\n",
    "\n",
    "    finally:\n",
    "        if driver:\n",
    "            driver.quit()\n",
    "\n",
    "    return jobs_data\n",
    "\n",
    "# Main function to scrape and save results to CSV\n",
    "def main(search_keyword=\"\", max_pages=20, headless=False):\n",
    "    start_time = time.time()\n",
    "    logger.info(f\"Starting Broadcom job scraper at {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "    \n",
    "    # Create screenshots directory\n",
    "    os.makedirs('screenshots', exist_ok=True)\n",
    "    \n",
    "    # Create job description screenshots directory\n",
    "    os.makedirs('job_description_screenshots', exist_ok=True)\n",
    "    \n",
    "    # Scrape Broadcom jobs\n",
    "    jobs_data = scrape_broadcom_jobs(search_keyword, max_pages, headless)\n",
    "    \n",
    "    # Generate filenames with timestamps\n",
    "    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "    keyword_slug = search_keyword.replace(' ', '_') if search_keyword else 'all'\n",
    "    detailed_filename = f\"broadcom_jobs_detailed_{keyword_slug}_{timestamp}.csv\"\n",
    "    simple_filename = f\"broadcom_jobs_simple_{keyword_slug}_{timestamp}.csv\"\n",
    "    \n",
    "    # Save results\n",
    "    if jobs_data:\n",
    "        # Create DataFrame\n",
    "        df = pd.DataFrame(jobs_data)\n",
    "        \n",
    "        # Save detailed CSV with descriptions\n",
    "        df.to_csv(detailed_filename, index=False, encoding='utf-8-sig')\n",
    "        logger.info(f\"Detailed jobs saved to '{detailed_filename}'\")\n",
    "        \n",
    "        # Create and save a simplified CSV without descriptions\n",
    "        simple_df = df[['Title', 'Location', 'Link']].copy()\n",
    "        simple_df.to_csv(simple_filename, index=False, encoding='utf-8-sig')\n",
    "        logger.info(f\"Simplified jobs list saved to '{simple_filename}'\")\n",
    "        \n",
    "        # Also create a filtered file if a search keyword was provided\n",
    "        if search_keyword:\n",
    "            filtered_df = df[df['Title'].str.contains(search_keyword, case=False)].copy()\n",
    "            filtered_filename = f\"broadcom_jobs_filtered_{keyword_slug}_{timestamp}.csv\"\n",
    "            filtered_df.to_csv(filtered_filename, index=False, encoding='utf-8-sig')\n",
    "            logger.info(f\"Jobs filtered by keyword '{search_keyword}' saved to '{filtered_filename}'\")\n",
    "            logger.info(f\"Found {len(filtered_df)} jobs matching the keyword out of {len(df)} total jobs\")\n",
    "        \n",
    "        # Print summary\n",
    "        print(\"\\n\" + \"=\"*50)\n",
    "        print(f\"Broadcom Job Scraping Results:\")\n",
    "        print(f\"Total jobs found: {len(df)}\")\n",
    "        print(f\"Unique locations: {len(df['Location'].unique())}\")\n",
    "        print(f\"Sample jobs:\")\n",
    "        print(df[['Title', 'Location']].head())\n",
    "        print(\"\\nTop locations:\")\n",
    "        print(df['Location'].value_counts().head())\n",
    "        print(f\"\\nResults saved to:\")\n",
    "        print(f\"- {detailed_filename}\")\n",
    "        print(f\"- {simple_filename}\")\n",
    "        if search_keyword:\n",
    "            print(f\"- {filtered_filename}\")\n",
    "        print(\"=\"*50)\n",
    "        \n",
    "        elapsed_time = time.time() - start_time\n",
    "        logger.info(f\"Completed in {elapsed_time:.2f} seconds\")\n",
    "        \n",
    "        return df\n",
    "    else:\n",
    "        logger.warning(f\"No jobs found with search keyword '{search_keyword}'\")\n",
    "        print(\"\\nNo jobs found to display.\")\n",
    "        \n",
    "        elapsed_time = time.time() - start_time\n",
    "        logger.info(f\"Process completed with no results in {elapsed_time:.2f} seconds\")\n",
    "        \n",
    "        return pd.DataFrame()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"Broadcom Job Scraper\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    # Get user input\n",
    "    job_title = input(\"Enter job title to search for (leave empty to get all jobs): \").strip()\n",
    "    \n",
    "   \n",
    "\n",
    "    try:\n",
    "        max_pages = int(input(\"Maximum number of pages to scrape (default 10): \") or \"10\")\n",
    "    except ValueError:\n",
    "        max_pages = 10\n",
    "        print(\"Invalid input. Using default of 10 pages.\")\n",
    "    \n",
    "    headless_mode = input(\"Run in headless mode? (y/n, default: n): \").strip().lower() == 'y'\n",
    "    \n",
    "    print(\"\\nStarting job scraper...\")\n",
    "    print(\"This may take several minutes depending on the number of jobs and pages.\")\n",
    "    print(\"Progress will be logged to the console and a log file.\")\n",
    "    \n",
    "    # Run the scraper\n",
    "    main(job_title, max_pages, headless_mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51e253f1-fd45-49fb-ac10-fe697def309b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
