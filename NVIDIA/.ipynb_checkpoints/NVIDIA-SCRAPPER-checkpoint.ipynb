{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eac026ce-441c-4eab-9df6-4d050eb412af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NVIDIA Job Scraper\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter job title to search for (leave empty to get all jobs):  Software Engineer\n",
      "Maximum number of pages to scrape (default 20):  2\n",
      "Run in headless mode? (y/n, default: n):  y\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-15 13:37:53,650 - INFO - Starting NVIDIA job scraper at 2025-03-15 13:37:53\n",
      "2025-03-15 13:37:53,653 - INFO - ====== WebDriver manager ======\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting job scraper...\n",
      "This may take several minutes depending on the number of jobs and pages.\n",
      "Progress will be logged to the console and a log file.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-15 13:37:54,353 - INFO - Get LATEST chromedriver version for google-chrome\n",
      "2025-03-15 13:37:54,425 - INFO - Get LATEST chromedriver version for google-chrome\n",
      "2025-03-15 13:37:54,480 - INFO - Driver [/Users/srikar/.wdm/drivers/chromedriver/mac64/134.0.6998.88/chromedriver-mac-arm64/chromedriver] found in cache\n",
      "2025-03-15 13:37:55,827 - INFO - Scraping jobs from NVIDIA, searching for 'Software Engineer'\n",
      "2025-03-15 13:37:59,010 - INFO - Job listings found with selector: [data-automation-id='jobTitle']\n",
      "2025-03-15 13:37:59,013 - INFO - Starting to scroll to load all content...\n",
      "2025-03-15 13:38:02,512 - INFO - Scroll 1: Height 4282 → 4282, Jobs found: 20\n",
      "2025-03-15 13:38:05,989 - INFO - Scroll 2: Height 4282 → 4282, Jobs found: 20\n",
      "2025-03-15 13:38:05,990 - INFO - No change detected (1/3)\n",
      "2025-03-15 13:38:09,466 - INFO - Scroll 3: Height 4282 → 4282, Jobs found: 20\n",
      "2025-03-15 13:38:09,466 - INFO - No change detected (2/3)\n",
      "2025-03-15 13:38:12,938 - INFO - Scroll 4: Height 4282 → 4282, Jobs found: 20\n",
      "2025-03-15 13:38:12,938 - INFO - No change detected (3/3)\n",
      "2025-03-15 13:38:12,939 - INFO - No more content loading after multiple scrolls. Stopping scroll operation.\n",
      "2025-03-15 13:38:12,939 - INFO - Completed scrolling after 3 scrolls. Found approximately 20 job items.\n",
      "2025-03-15 13:38:13,338 - INFO - Starting pagination handling...\n",
      "2025-03-15 13:38:13,338 - INFO - Processing page 1\n",
      "2025-03-15 13:38:13,750 - INFO - Job listings found with selector: [data-automation-id='jobTitle']\n",
      "2025-03-15 13:38:13,756 - INFO - Found 20 job elements using selector: [data-automation-id='jobTitle']\n",
      "2025-03-15 13:38:14,266 - INFO - Added job: Software Engineer at © 2025 Workday, Inc. All rights reserved.\n",
      "2025-03-15 13:38:14,314 - INFO - Added job: Senior Software Engineer at © 2025 Workday, Inc. All rights reserved.\n",
      "2025-03-15 13:38:14,360 - INFO - Added job: Senior Software Engineer at © 2025 Workday, Inc. All rights reserved.\n",
      "2025-03-15 13:38:14,408 - INFO - Added job: Senior Software Engineer at © 2025 Workday, Inc. All rights reserved.\n",
      "2025-03-15 13:38:14,463 - INFO - Added job: Automation Software Engineer at © 2025 Workday, Inc. All rights reserved.\n",
      "2025-03-15 13:38:14,509 - INFO - Added job: Senior Software Engineer at © 2025 Workday, Inc. All rights reserved.\n",
      "2025-03-15 13:38:14,555 - INFO - Added job: System Software Engineer at © 2025 Workday, Inc. All rights reserved.\n",
      "2025-03-15 13:38:14,601 - INFO - Added job: Manager, Software Engineering at © 2025 Workday, Inc. All rights reserved.\n",
      "2025-03-15 13:38:14,648 - INFO - Added job: Senior Software Engineer at © 2025 Workday, Inc. All rights reserved.\n",
      "2025-03-15 13:38:14,695 - INFO - Added job: Senior Software Engineer at © 2025 Workday, Inc. All rights reserved.\n",
      "2025-03-15 13:38:14,741 - INFO - Added job: Senior Performance Software Engineer at © 2025 Workday, Inc. All rights reserved.\n",
      "2025-03-15 13:38:14,790 - INFO - Added job: Software Engineering Manager - Libraries at © 2025 Workday, Inc. All rights reserved.\n",
      "2025-03-15 13:38:14,834 - INFO - Added job: EDA System Software Engineer at © 2025 Workday, Inc. All rights reserved.\n",
      "2025-03-15 13:38:14,879 - INFO - Added job: Senior Software Engineer - HPC at © 2025 Workday, Inc. All rights reserved.\n",
      "2025-03-15 13:38:14,926 - INFO - Added job: Senior Software Engineer - Backend at © 2025 Workday, Inc. All rights reserved.\n",
      "2025-03-15 13:38:14,973 - INFO - Added job: Senior System Software Engineer at © 2025 Workday, Inc. All rights reserved.\n",
      "2025-03-15 13:38:15,019 - INFO - Added job: Graphics Tools Software Engineer at © 2025 Workday, Inc. All rights reserved.\n",
      "2025-03-15 13:38:15,069 - INFO - Added job: Senior System Software Engineer at © 2025 Workday, Inc. All rights reserved.\n",
      "2025-03-15 13:38:15,114 - INFO - Added job: Senior Software Engineer - Networking at © 2025 Workday, Inc. All rights reserved.\n",
      "2025-03-15 13:38:15,160 - INFO - Added job: Senior Systems Software Engineer at © 2025 Workday, Inc. All rights reserved.\n",
      "2025-03-15 13:38:15,161 - INFO - Found 20 jobs on page 1\n",
      "2025-03-15 13:38:15,253 - INFO - Clicked next page button\n",
      "2025-03-15 13:38:20,269 - INFO - Job listings found with selector: [data-automation-id='jobTitle']\n",
      "2025-03-15 13:38:20,873 - INFO - Processing page 2\n",
      "2025-03-15 13:38:21,441 - INFO - Job listings found with selector: [data-automation-id='jobTitle']\n",
      "2025-03-15 13:38:21,447 - INFO - Found 20 job elements using selector: [data-automation-id='jobTitle']\n",
      "2025-03-15 13:38:22,073 - INFO - Added job: Software Engineering Intern - 2025 at China, Shanghai\n",
      "2025-03-15 13:38:22,106 - INFO - Added job: Software Engineering Intern - OpenBMC at China, Shanghai\n",
      "2025-03-15 13:38:22,139 - INFO - Added job: Senior Manager, Software Engineering at China, Shanghai\n",
      "2025-03-15 13:38:22,172 - INFO - Added job: Senior C++ Software Engineer at China, Shanghai\n",
      "2025-03-15 13:38:22,205 - INFO - Added job: System Software Engineer - CUDA Driver at China, Shanghai\n",
      "2025-03-15 13:38:22,238 - INFO - Added job: Senior Full-Stack Software Engineer at China, Shanghai\n",
      "2025-03-15 13:38:22,271 - INFO - Added job: Senior Software Engineer – Build Tools at China, Shanghai\n",
      "2025-03-15 13:38:22,304 - INFO - Added job: Senior Platform Software Engineer, PCIe at China, Shanghai\n",
      "2025-03-15 13:38:22,338 - INFO - Added job: Senior System Profiling Software Engineer at China, Shanghai\n",
      "2025-03-15 13:38:22,373 - INFO - Added job: Senior GPU Cluster Software Engineer at China, Shanghai\n",
      "2025-03-15 13:38:22,408 - INFO - Added job: VLSI Design Automation Software Engineer at China, Shanghai\n",
      "2025-03-15 13:38:22,444 - INFO - Added job: Senior Generalist Software Engineer -- Omniverse at China, Shanghai\n",
      "2025-03-15 13:38:22,479 - INFO - Added job: Senior Software Engineer - CUDA Python at China, Shanghai\n",
      "2025-03-15 13:38:22,514 - INFO - Added job: Senior System Software Engineer - Tegra at China, Shanghai\n",
      "2025-03-15 13:38:22,549 - INFO - Added job: NVIDIA 2025 Internships: Software Engineering at China, Shanghai\n",
      "2025-03-15 13:38:22,585 - INFO - Added job: Senior Software Engineer - Triton Tools at China, Shanghai\n",
      "2025-03-15 13:38:22,621 - INFO - Added job: Software Engineer - Robot Learning Platform at China, Shanghai\n",
      "2025-03-15 13:38:22,656 - INFO - Added job: Tegra Software Engineer (RDSS Intern) at China, Shanghai\n",
      "2025-03-15 13:38:22,691 - INFO - Added job: Software Engineering Intern - Autonomous Vehicles at China, Shanghai\n",
      "2025-03-15 13:38:22,726 - INFO - Added job: Software Engineering Intern - Autonomous Vehicles at China, Shanghai\n",
      "2025-03-15 13:38:22,727 - INFO - Found 20 jobs on page 2\n",
      "2025-03-15 13:38:22,800 - INFO - Clicked next page button\n",
      "2025-03-15 13:38:27,817 - INFO - Job listings found with selector: [data-automation-id='jobTitle']\n",
      "2025-03-15 13:38:28,413 - INFO - Collected 40 total jobs after pagination\n",
      "2025-03-15 13:38:28,413 - INFO - Getting descriptions for 40 jobs (up to 200)\n",
      "2025-03-15 13:38:28,417 - INFO - Getting description for job 1/40: Software Engineer\n",
      "2025-03-15 13:38:35,377 - INFO - Saved full-page screenshot to job_description_screenshots/job_1_Software_Engineer.png\n",
      "2025-03-15 13:38:40,628 - INFO - Getting description for job 2/40: Senior Software Engineer\n",
      "2025-03-15 13:38:47,230 - INFO - Saved full-page screenshot to job_description_screenshots/job_2_Senior_Software_Engineer.png\n",
      "2025-03-15 13:38:52,491 - INFO - Getting description for job 3/40: Senior Software Engineer\n",
      "2025-03-15 13:38:59,072 - INFO - Saved full-page screenshot to job_description_screenshots/job_3_Senior_Software_Engineer.png\n",
      "2025-03-15 13:39:04,291 - INFO - Getting description for job 4/40: Senior Software Engineer\n",
      "2025-03-15 13:39:10,897 - INFO - Saved full-page screenshot to job_description_screenshots/job_4_Senior_Software_Engineer.png\n",
      "2025-03-15 13:39:15,895 - INFO - Getting description for job 5/40: Automation Software Engineer\n",
      "2025-03-15 13:39:22,412 - INFO - Saved full-page screenshot to job_description_screenshots/job_5_Automation_Software_Engineer.png\n",
      "2025-03-15 13:39:27,318 - INFO - Getting description for job 6/40: Senior Software Engineer\n",
      "2025-03-15 13:39:34,174 - INFO - Saved full-page screenshot to job_description_screenshots/job_6_Senior_Software_Engineer.png\n",
      "2025-03-15 13:39:39,372 - INFO - Getting description for job 7/40: System Software Engineer\n",
      "2025-03-15 13:39:45,956 - INFO - Saved full-page screenshot to job_description_screenshots/job_7_System_Software_Engineer.png\n",
      "2025-03-15 13:39:51,136 - INFO - Getting description for job 8/40: Manager, Software Engineering\n",
      "2025-03-15 13:39:57,832 - INFO - Saved full-page screenshot to job_description_screenshots/job_8_Manager,_Software_Engineering.png\n",
      "2025-03-15 13:40:03,289 - INFO - Getting description for job 9/40: Senior Software Engineer\n",
      "2025-03-15 13:40:10,086 - INFO - Saved full-page screenshot to job_description_screenshots/job_9_Senior_Software_Engineer.png\n",
      "2025-03-15 13:40:15,481 - INFO - Getting description for job 10/40: Senior Software Engineer\n",
      "2025-03-15 13:40:22,040 - INFO - Saved full-page screenshot to job_description_screenshots/job_10_Senior_Software_Engineer.png\n",
      "2025-03-15 13:40:27,254 - INFO - Getting description for job 11/40: Senior Performance Software Engineer\n",
      "2025-03-15 13:40:33,991 - INFO - Saved full-page screenshot to job_description_screenshots/job_11_Senior_Performance_Software_Engineer.png\n",
      "2025-03-15 13:40:39,581 - INFO - Getting description for job 12/40: Software Engineering Manager - Libraries\n",
      "2025-03-15 13:40:46,357 - INFO - Saved full-page screenshot to job_description_screenshots/job_12_Software_Engineering_Manager_-_Libraries.png\n",
      "2025-03-15 13:40:51,883 - INFO - Getting description for job 13/40: EDA System Software Engineer\n",
      "2025-03-15 13:40:58,715 - INFO - Saved full-page screenshot to job_description_screenshots/job_13_EDA_System_Software_Engineer.png\n",
      "2025-03-15 13:41:04,072 - INFO - Getting description for job 14/40: Senior Software Engineer - HPC\n",
      "2025-03-15 13:41:10,944 - INFO - Saved full-page screenshot to job_description_screenshots/job_14_Senior_Software_Engineer_-_HPC.png\n",
      "2025-03-15 13:41:16,505 - INFO - Getting description for job 15/40: Senior Software Engineer - Backend\n",
      "2025-03-15 13:41:23,241 - INFO - Saved full-page screenshot to job_description_screenshots/job_15_Senior_Software_Engineer_-_Backend.png\n",
      "2025-03-15 13:41:28,639 - INFO - Getting description for job 16/40: Senior System Software Engineer\n",
      "2025-03-15 13:41:35,477 - INFO - Saved full-page screenshot to job_description_screenshots/job_16_Senior_System_Software_Engineer.png\n",
      "2025-03-15 13:41:41,233 - INFO - Getting description for job 17/40: Graphics Tools Software Engineer\n",
      "2025-03-15 13:41:48,257 - INFO - Saved full-page screenshot to job_description_screenshots/job_17_Graphics_Tools_Software_Engineer.png\n",
      "2025-03-15 13:41:54,083 - INFO - Getting description for job 18/40: Senior System Software Engineer\n",
      "2025-03-15 13:42:00,948 - INFO - Saved full-page screenshot to job_description_screenshots/job_18_Senior_System_Software_Engineer.png\n",
      "2025-03-15 13:42:06,649 - INFO - Getting description for job 19/40: Senior Software Engineer - Networking\n",
      "2025-03-15 13:42:13,304 - INFO - Saved full-page screenshot to job_description_screenshots/job_19_Senior_Software_Engineer_-_Networking.png\n",
      "2025-03-15 13:42:18,732 - INFO - Getting description for job 20/40: Senior Systems Software Engineer\n",
      "2025-03-15 13:42:25,749 - INFO - Saved full-page screenshot to job_description_screenshots/job_20_Senior_Systems_Software_Engineer.png\n",
      "2025-03-15 13:42:31,232 - INFO - Getting description for job 21/40: Software Engineering Intern - 2025\n",
      "2025-03-15 13:42:37,800 - INFO - Saved full-page screenshot to job_description_screenshots/job_21_Software_Engineering_Intern_-_2025.png\n",
      "2025-03-15 13:42:43,106 - INFO - Getting description for job 22/40: Software Engineering Intern - OpenBMC\n",
      "2025-03-15 13:42:49,634 - INFO - Saved full-page screenshot to job_description_screenshots/job_22_Software_Engineering_Intern_-_OpenBMC.png\n",
      "2025-03-15 13:42:54,733 - INFO - Getting description for job 23/40: Senior Manager, Software Engineering\n",
      "2025-03-15 13:43:01,444 - INFO - Saved full-page screenshot to job_description_screenshots/job_23_Senior_Manager,_Software_Engineering.png\n",
      "2025-03-15 13:43:06,729 - INFO - Getting description for job 24/40: Senior C++ Software Engineer\n",
      "2025-03-15 13:43:13,502 - INFO - Saved full-page screenshot to job_description_screenshots/job_24_Senior_C++_Software_Engineer.png\n",
      "2025-03-15 13:43:19,567 - INFO - Getting description for job 25/40: System Software Engineer - CUDA Driver\n",
      "2025-03-15 13:43:26,266 - INFO - Saved full-page screenshot to job_description_screenshots/job_25_System_Software_Engineer_-_CUDA_Driver.png\n",
      "2025-03-15 13:43:31,498 - INFO - Getting description for job 26/40: Senior Full-Stack Software Engineer\n",
      "2025-03-15 13:43:38,110 - INFO - Saved full-page screenshot to job_description_screenshots/job_26_Senior_Full-Stack_Software_Engineer.png\n",
      "2025-03-15 13:43:43,427 - INFO - Getting description for job 27/40: Senior Software Engineer – Build Tools\n",
      "2025-03-15 13:43:49,983 - INFO - Saved full-page screenshot to job_description_screenshots/job_27_Senior_Software_Engineer_–_Build_Tools.png\n",
      "2025-03-15 13:43:55,054 - INFO - Getting description for job 28/40: Senior Platform Software Engineer, PCIe\n",
      "2025-03-15 13:44:01,827 - INFO - Saved full-page screenshot to job_description_screenshots/job_28_Senior_Platform_Software_Engineer,_PCIe.png\n",
      "2025-03-15 13:44:07,548 - INFO - Getting description for job 29/40: Senior System Profiling Software Engineer\n",
      "2025-03-15 13:44:14,449 - INFO - Saved full-page screenshot to job_description_screenshots/job_29_Senior_System_Profiling_Software_Engineer.png\n",
      "2025-03-15 13:44:20,007 - INFO - Getting description for job 30/40: Senior GPU Cluster Software Engineer\n",
      "2025-03-15 13:44:26,788 - INFO - Saved full-page screenshot to job_description_screenshots/job_30_Senior_GPU_Cluster_Software_Engineer.png\n",
      "2025-03-15 13:44:32,228 - INFO - Getting description for job 31/40: VLSI Design Automation Software Engineer\n",
      "2025-03-15 13:44:38,881 - INFO - Saved full-page screenshot to job_description_screenshots/job_31_VLSI_Design_Automation_Software_Engineer.png\n",
      "2025-03-15 13:44:44,397 - INFO - Getting description for job 32/40: Senior Generalist Software Engineer -- Omniverse\n",
      "2025-03-15 13:44:51,182 - INFO - Saved full-page screenshot to job_description_screenshots/job_32_Senior_Generalist_Software_Engineer_--_Omniverse.png\n",
      "2025-03-15 13:44:56,903 - INFO - Getting description for job 33/40: Senior Software Engineer - CUDA Python\n",
      "2025-03-15 13:45:04,034 - INFO - Saved full-page screenshot to job_description_screenshots/job_33_Senior_Software_Engineer_-_CUDA_Python.png\n",
      "2025-03-15 13:45:10,645 - INFO - Getting description for job 34/40: Senior System Software Engineer - Tegra\n",
      "2025-03-15 13:45:17,505 - INFO - Saved full-page screenshot to job_description_screenshots/job_34_Senior_System_Software_Engineer_-_Tegra.png\n",
      "2025-03-15 13:45:25,461 - INFO - Getting description for job 35/40: NVIDIA 2025 Internships: Software Engineering\n",
      "2025-03-15 13:45:32,559 - INFO - Saved full-page screenshot to job_description_screenshots/job_35_NVIDIA_2025_Internships_Software_Engineering.png\n",
      "2025-03-15 13:45:38,869 - INFO - Getting description for job 36/40: Senior Software Engineer - Triton Tools\n",
      "2025-03-15 13:45:45,829 - INFO - Saved full-page screenshot to job_description_screenshots/job_36_Senior_Software_Engineer_-_Triton_Tools.png\n",
      "2025-03-15 13:45:52,141 - INFO - Getting description for job 37/40: Software Engineer - Robot Learning Platform\n",
      "2025-03-15 13:45:58,920 - INFO - Saved full-page screenshot to job_description_screenshots/job_37_Software_Engineer_-_Robot_Learning_Platform.png\n",
      "2025-03-15 13:46:04,821 - INFO - Getting description for job 38/40: Tegra Software Engineer (RDSS Intern)\n",
      "2025-03-15 13:46:11,627 - INFO - Saved full-page screenshot to job_description_screenshots/job_38_Tegra_Software_Engineer_(RDSS_Intern).png\n",
      "2025-03-15 13:46:17,430 - INFO - Getting description for job 39/40: Software Engineering Intern - Autonomous Vehicles\n",
      "2025-03-15 13:46:24,063 - INFO - Saved full-page screenshot to job_description_screenshots/job_39_Software_Engineering_Intern_-_Autonomous_Vehicles.png\n",
      "2025-03-15 13:46:29,576 - INFO - Getting description for job 40/40: Software Engineering Intern - Autonomous Vehicles\n",
      "2025-03-15 13:46:36,238 - INFO - Saved full-page screenshot to job_description_screenshots/job_40_Software_Engineering_Intern_-_Autonomous_Vehicles.png\n",
      "2025-03-15 13:46:44,912 - INFO - Completed fetching descriptions for 40 jobs\n",
      "2025-03-15 13:46:44,916 - INFO - Saving all 40 jobs found in search results\n",
      "2025-03-15 13:46:45,095 - INFO - Detailed jobs saved to 'nvidia_jobs_detailed_Software_Engineer_20250315_134645.csv'\n",
      "2025-03-15 13:46:45,104 - INFO - Simplified jobs list saved to 'nvidia_jobs_simple_Software_Engineer_20250315_134645.csv'\n",
      "2025-03-15 13:46:45,108 - INFO - Jobs filtered by keyword 'Software Engineer' saved to 'nvidia_jobs_filtered_Software_Engineer_20250315_134645.csv'\n",
      "2025-03-15 13:46:45,108 - INFO - Found 40 jobs matching the keyword out of 40 total jobs\n",
      "2025-03-15 13:46:45,112 - INFO - Completed in 531.46 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "NVIDIA Job Scraping Results:\n",
      "Total jobs found: 40\n",
      "Unique locations: 2\n",
      "Sample jobs:\n",
      "                          Title                                   Location\n",
      "0             Software Engineer  © 2025 Workday, Inc. All rights reserved.\n",
      "1      Senior Software Engineer  © 2025 Workday, Inc. All rights reserved.\n",
      "2      Senior Software Engineer  © 2025 Workday, Inc. All rights reserved.\n",
      "3      Senior Software Engineer  © 2025 Workday, Inc. All rights reserved.\n",
      "4  Automation Software Engineer  © 2025 Workday, Inc. All rights reserved.\n",
      "\n",
      "Top locations:\n",
      "Location\n",
      "© 2025 Workday, Inc. All rights reserved.    20\n",
      "China, Shanghai                              20\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Results saved to:\n",
      "- nvidia_jobs_detailed_Software_Engineer_20250315_134645.csv\n",
      "- nvidia_jobs_simple_Software_Engineer_20250315_134645.csv\n",
      "- nvidia_jobs_filtered_Software_Engineer_20250315_134645.csv\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.alert import Alert\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.common.exceptions import TimeoutException, NoSuchElementException, StaleElementReferenceException\n",
    "import pandas as pd\n",
    "import time\n",
    "import requests\n",
    "import logging\n",
    "import re\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO, \n",
    "                    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "                    handlers=[\n",
    "                        logging.FileHandler(f\"job_scraper_{datetime.now().strftime('%Y%m%d_%H%M%S')}.log\"),\n",
    "                        logging.StreamHandler()\n",
    "                    ])\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Function to scroll and load all jobs with improved logic\n",
    "def scroll_to_load_all(driver, max_scrolls=30, wait_time=2):\n",
    "    \"\"\"\n",
    "    Scroll the page to load all content with a maximum number of scrolls\n",
    "    For NVIDIA's Workday-based site, which loads content dynamically\n",
    "    \"\"\"\n",
    "    scrolls = 0\n",
    "    last_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "    last_job_count = 0\n",
    "    consecutive_no_change = 0\n",
    "    \n",
    "    logger.info(\"Starting to scroll to load all content...\")\n",
    "    \n",
    "    while scrolls < max_scrolls:\n",
    "        # Scroll down\n",
    "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "        time.sleep(wait_time)  # Wait time for content to load\n",
    "        \n",
    "        # Take screenshot for debugging\n",
    "        driver.save_screenshot(f\"screenshots/scroll_{scrolls+1}.png\")\n",
    "        \n",
    "        # Try to find the \"Load More\" or similar buttons and click them\n",
    "        try:\n",
    "            load_more_buttons = driver.find_elements(By.XPATH, \n",
    "                \"//button[contains(text(), 'Load More') or contains(text(), 'Show More') or contains(@aria-label, 'Load') or contains(@class, 'load-more')]\")\n",
    "            if load_more_buttons:\n",
    "                for button in load_more_buttons:\n",
    "                    if button.is_displayed() and button.is_enabled():\n",
    "                        driver.execute_script(\"arguments[0].click();\", button)\n",
    "                        logger.info(\"Clicked 'Load More' button\")\n",
    "                        time.sleep(wait_time + 1)  # Extra wait for new content\n",
    "        except Exception as e:\n",
    "            logger.info(f\"No 'Load More' button found or error clicking it: {e}\")\n",
    "        \n",
    "        # Check height and job count to determine if we've loaded all content\n",
    "        new_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "        \n",
    "        # Try different job card selectors to get an accurate count\n",
    "        job_selectors = [\n",
    "            \"[data-automation-id='jobTitle']\", \n",
    "            \".WGDC\", \n",
    "            \"[role='listitem']\",\n",
    "            \".css-19uc56f\",\n",
    "            \".css-1q6t3sv div[role='row']\"\n",
    "        ]\n",
    "        \n",
    "        current_job_count = 0\n",
    "        for selector in job_selectors:\n",
    "            count = len(driver.find_elements(By.CSS_SELECTOR, selector))\n",
    "            if count > current_job_count:\n",
    "                current_job_count = count\n",
    "        \n",
    "        logger.info(f\"Scroll {scrolls+1}: Height {last_height} → {new_height}, Jobs found: {current_job_count}\")\n",
    "        \n",
    "        # If no change in height and job count, we might have reached the end\n",
    "        if new_height == last_height and current_job_count == last_job_count:\n",
    "            consecutive_no_change += 1\n",
    "            logger.info(f\"No change detected ({consecutive_no_change}/3)\")\n",
    "            if consecutive_no_change >= 3:  # If no change for 3 consecutive scrolls\n",
    "                logger.info(\"No more content loading after multiple scrolls. Stopping scroll operation.\")\n",
    "                break\n",
    "        else:\n",
    "            consecutive_no_change = 0\n",
    "            \n",
    "        last_height = new_height\n",
    "        last_job_count = current_job_count\n",
    "        scrolls += 1\n",
    "    \n",
    "    logger.info(f\"Completed scrolling after {scrolls} scrolls. Found approximately {last_job_count} job items.\")\n",
    "    return last_job_count\n",
    "\n",
    "# Function to handle pagination for NVIDIA Workday\n",
    "def handle_pagination(driver, max_pages=20):\n",
    "    \"\"\"\n",
    "    Handle pagination by clicking through all available pages\n",
    "    \"\"\"\n",
    "    page = 1\n",
    "    all_jobs = []\n",
    "    \n",
    "    logger.info(\"Starting pagination handling...\")\n",
    "    \n",
    "    while page <= max_pages:\n",
    "        logger.info(f\"Processing page {page}\")\n",
    "        \n",
    "        # Take screenshot for debugging\n",
    "        driver.save_screenshot(f\"screenshots/page_{page}.png\")\n",
    "        \n",
    "        # Wait for job listings to be visible \n",
    "        wait_for_job_listings(driver)\n",
    "        \n",
    "        # Extract current page's jobs\n",
    "        jobs_on_page = extract_job_listings_nvidia(driver)\n",
    "        all_jobs.extend(jobs_on_page)\n",
    "        logger.info(f\"Found {len(jobs_on_page)} jobs on page {page}\")\n",
    "        \n",
    "        # Look for next page button - try multiple selectors\n",
    "        next_selectors = [\n",
    "            \"[aria-label='next page']\", \n",
    "            \"[data-automation-id='paginationNextButton']\",\n",
    "            \"button[title='Next Page']\",\n",
    "            \"button.css-1ddxsuf\",\n",
    "            \"button.next-page\",\n",
    "            \"//button[contains(@class, 'page') and contains(@class, 'next')]\",\n",
    "            \"//button[contains(@aria-label, 'next')]\"\n",
    "        ]\n",
    "        \n",
    "        next_button = None\n",
    "        for selector in next_selectors:\n",
    "            try:\n",
    "                if selector.startswith(\"//\"):\n",
    "                    elements = driver.find_elements(By.XPATH, selector)\n",
    "                else:\n",
    "                    elements = driver.find_elements(By.CSS_SELECTOR, selector)\n",
    "                \n",
    "                for elem in elements:\n",
    "                    if elem.is_displayed() and not (elem.get_attribute(\"disabled\") or \"disabled\" in elem.get_attribute(\"class\") or \"inactive\" in elem.get_attribute(\"class\")):\n",
    "                        next_button = elem\n",
    "                        break\n",
    "                        \n",
    "                if next_button:\n",
    "                    break\n",
    "            except Exception:\n",
    "                continue\n",
    "        \n",
    "        if not next_button:\n",
    "            logger.info(\"No next page button found. Reached last page.\")\n",
    "            break\n",
    "            \n",
    "        # Check if button is disabled (end of pages)\n",
    "        if next_button.get_attribute(\"disabled\") or \"disabled\" in next_button.get_attribute(\"class\"):\n",
    "            logger.info(\"Reached last page - Next button is disabled\")\n",
    "            break\n",
    "            \n",
    "        # Click next page using JavaScript to avoid intercept issues\n",
    "        try:\n",
    "            driver.execute_script(\"arguments[0].click();\", next_button)\n",
    "            logger.info(\"Clicked next page button\")\n",
    "            time.sleep(5)  # Wait for page to load\n",
    "            page += 1\n",
    "            \n",
    "            # Wait for job listings to reload\n",
    "            wait_for_job_listings(driver)\n",
    "            \n",
    "            # Take screenshot after page change\n",
    "            driver.save_screenshot(f\"screenshots/page_{page}_loaded.png\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error clicking next page: {e}\")\n",
    "            # Try one more time with a different approach\n",
    "            try:\n",
    "                driver.execute_script(\"arguments[0].scrollIntoView(true);\", next_button)\n",
    "                time.sleep(1)\n",
    "                next_button.click()\n",
    "                logger.info(\"Clicked next page button using alternative method\")\n",
    "                time.sleep(5)\n",
    "                page += 1\n",
    "            except Exception as e2:\n",
    "                logger.error(f\"Still failed to click next page: {e2}\")\n",
    "                break\n",
    "            \n",
    "    return all_jobs\n",
    "\n",
    "# Helper function to wait for job listings to appear\n",
    "def wait_for_job_listings(driver, timeout=15):\n",
    "    \"\"\"Wait for job listings to appear on the page using multiple possible selectors\"\"\"\n",
    "    selectors = [\n",
    "        \"[data-automation-id='jobTitle']\",\n",
    "        \".WGDC\",\n",
    "        \"[role='listitem']\",\n",
    "        \".css-19uc56f\",\n",
    "        \".css-1q6t3sv div[role='row']\",\n",
    "        \"ul[role='list'] li\"\n",
    "    ]\n",
    "    \n",
    "    for selector in selectors:\n",
    "        try:\n",
    "            WebDriverWait(driver, timeout).until(\n",
    "                EC.presence_of_element_located((By.CSS_SELECTOR, selector))\n",
    "            )\n",
    "            logger.info(f\"Job listings found with selector: {selector}\")\n",
    "            return True\n",
    "        except TimeoutException:\n",
    "            continue\n",
    "    \n",
    "    logger.warning(\"Could not detect job listings with any known selector\")\n",
    "    return False\n",
    "\n",
    "# Extract job information from NVIDIA page\n",
    "def extract_job_listings_nvidia(driver):\n",
    "    \"\"\"\n",
    "    Extract job listings from NVIDIA Workday page\n",
    "    Handles different potential Workday UI structures\n",
    "    \"\"\"\n",
    "    jobs_data = []\n",
    "    \n",
    "    # Try different selectors for job elements \n",
    "    selectors = [\n",
    "        # Primary Workday selectors\n",
    "        {\"container\": \"[data-automation-id='jobTitle']\", \"type\": \"primary\"},\n",
    "        {\"container\": \"[data-automation-id='job-card']\", \"type\": \"primary\"},\n",
    "        {\"container\": \".css-1q6t3sv [role='row']\", \"type\": \"row\"},\n",
    "        {\"container\": \"ul[role='list'] > li\", \"type\": \"list\"}, \n",
    "        {\"container\": \".WGDC a[role='link']\", \"type\": \"link\"}\n",
    "    ]\n",
    "    \n",
    "    job_elements = []\n",
    "    used_selector = None\n",
    "    \n",
    "    # Try each selector to find job elements\n",
    "    for selector in selectors:\n",
    "        try:\n",
    "            elements = driver.find_elements(By.CSS_SELECTOR, selector[\"container\"])\n",
    "            if elements and len(elements) > 0:\n",
    "                job_elements = elements\n",
    "                used_selector = selector\n",
    "                logger.info(f\"Found {len(elements)} job elements using selector: {selector['container']}\")\n",
    "                \n",
    "                # Take a screenshot of the found elements (for debugging)\n",
    "                if len(elements) > 0:\n",
    "                    try:\n",
    "                        driver.execute_script(\"arguments[0].style.border='3px solid red'\", elements[0])\n",
    "                        driver.save_screenshot(\"screenshots/job_elements_found.png\")\n",
    "                        driver.execute_script(\"arguments[0].style.border=''\", elements[0])\n",
    "                    except:\n",
    "                        pass\n",
    "                break\n",
    "        except Exception as e:\n",
    "            logger.debug(f\"Selector {selector['container']} failed: {e}\")\n",
    "            continue\n",
    "    \n",
    "    if not job_elements:\n",
    "        logger.warning(\"Could not find job elements with any selector. Taking screenshot for debugging.\")\n",
    "        driver.save_screenshot(\"screenshots/no_job_elements.png\")\n",
    "        return jobs_data\n",
    "    \n",
    "    # Extract detailed information for each job based on the selector type\n",
    "    for index, job in enumerate(job_elements):\n",
    "        try:\n",
    "            # Different extraction logic based on which selector worked\n",
    "            if used_selector[\"type\"] == \"primary\":  # Standard Workday implementation\n",
    "                title_element = job if \"jobTitle\" in used_selector[\"container\"] else job.find_element(By.CSS_SELECTOR, \"[data-automation-id='jobTitle']\")\n",
    "                title = title_element.text.strip()\n",
    "                link = title_element.get_attribute(\"href\")\n",
    "                \n",
    "                # Try to find location near the job title element\n",
    "                location = \"Not specified\"\n",
    "                try:\n",
    "                    # Find parent card or container\n",
    "                    parent_card = None\n",
    "                    try:\n",
    "                        parent_card = title_element.find_element(By.XPATH, \"ancestor::div[contains(@class, 'css-') and @data-automation-id]\")\n",
    "                    except:\n",
    "                        parent_card = title_element.find_element(By.XPATH, \"./ancestor::*[3]\")  # Go up a few levels\n",
    "                    \n",
    "                    # Try multiple location selectors\n",
    "                    location_selectors = [\n",
    "                        \"[data-automation-id='location']\", \n",
    "                        \"[data-automation-id='locationLabel']\",\n",
    "                        \".css-1wzygq\",\n",
    "                        \".css-129m7dg\",\n",
    "                        \"//span[contains(text(), ',')]\",\n",
    "                        \"//div[contains(text(), ',')]\"\n",
    "                    ]\n",
    "                    \n",
    "                    for loc_selector in location_selectors:\n",
    "                        try:\n",
    "                            if loc_selector.startswith(\"//\"):\n",
    "                                location_elem = parent_card.find_element(By.XPATH, loc_selector)\n",
    "                            else:\n",
    "                                location_elem = parent_card.find_element(By.CSS_SELECTOR, loc_selector)\n",
    "                                \n",
    "                            if location_elem:\n",
    "                                location = location_elem.text.strip()\n",
    "                                if location and (\",\" in location or \"Remote\" in location):\n",
    "                                    break\n",
    "                        except:\n",
    "                            continue\n",
    "                except Exception as e:\n",
    "                    logger.debug(f\"Could not find location with primary selectors: {e}\")\n",
    "                    # Fallback: look for any element that mentions location\n",
    "                    try:\n",
    "                        # Look for elements after the title with location formatting \n",
    "                        location_candidates = driver.find_elements(By.XPATH, \n",
    "                            f\"//div[contains(text(), '{title}')]/following::div[contains(text(), ',') or contains(text(), 'Remote')]\")\n",
    "                        if location_candidates:\n",
    "                            location = location_candidates[0].text.strip()\n",
    "                    except:\n",
    "                        pass\n",
    "                \n",
    "            elif used_selector[\"type\"] in [\"row\", \"list\", \"link\"]:  # Generic extraction for other selectors\n",
    "                # Find title element\n",
    "                title_elem = None\n",
    "                title_selectors = [\"a\", \"h3\", \"[title]\", \"[aria-label]\", \"span.css-srrtrq\"]\n",
    "                \n",
    "                for t_selector in title_selectors:\n",
    "                    try:\n",
    "                        title_candidates = job.find_elements(By.CSS_SELECTOR, t_selector)\n",
    "                        for elem in title_candidates:\n",
    "                            text = elem.text.strip() or elem.get_attribute(\"title\") or elem.get_attribute(\"aria-label\")\n",
    "                            if text and len(text) > 3:  # Ensure it's substantial text\n",
    "                                title_elem = elem\n",
    "                                break\n",
    "                        if title_elem:\n",
    "                            break\n",
    "                    except:\n",
    "                        continue\n",
    "                        \n",
    "                if not title_elem:\n",
    "                    logger.debug(f\"Could not find title for job {index+1}\")\n",
    "                    continue\n",
    "                    \n",
    "                title = title_elem.text.strip() or title_elem.get_attribute(\"title\") or title_elem.get_attribute(\"aria-label\")\n",
    "                link = title_elem.get_attribute(\"href\")\n",
    "                \n",
    "                if not link:\n",
    "                    # Try to find a parent or sibling with a link\n",
    "                    link_containers = job.find_elements(By.CSS_SELECTOR, \"a\")\n",
    "                    if link_containers:\n",
    "                        link = link_containers[0].get_attribute(\"href\")\n",
    "                \n",
    "                # Try to find location\n",
    "                location = \"Not specified\"\n",
    "                try:\n",
    "                    # Look for location in various ways\n",
    "                    location_patterns = [\n",
    "                        \".//span[contains(text(), ',')]\",\n",
    "                        \".//div[contains(text(), ',')]\",\n",
    "                        \".//div[contains(text(), 'Location')]//following-sibling::div\",\n",
    "                        \".//span[contains(text(), 'Remote')]\",\n",
    "                        \".//div[contains(@class, 'location')]\"\n",
    "                    ]\n",
    "                    \n",
    "                    for pattern in location_patterns:\n",
    "                        location_elems = job.find_elements(By.XPATH, pattern)\n",
    "                        if location_elems:\n",
    "                            location = location_elems[0].text.strip()\n",
    "                            if location and len(location) > 2:  # Ensure it's not empty\n",
    "                                break\n",
    "                except Exception as e:\n",
    "                    logger.debug(f\"Could not find location with alternative selectors: {e}\")\n",
    "            \n",
    "            # Add the extracted job if we have at least a title and link\n",
    "            if title and title.strip() and link and link.strip():\n",
    "                # Check for duplicate before adding\n",
    "                is_duplicate = False\n",
    "                for existing_job in jobs_data:\n",
    "                    if existing_job[\"Title\"] == title and existing_job[\"Link\"] == link:\n",
    "                        is_duplicate = True\n",
    "                        break\n",
    "                \n",
    "                if not is_duplicate:\n",
    "                    jobs_data.append({\n",
    "                        \"Title\": title,\n",
    "                        \"Location\": location,\n",
    "                        \"Link\": link,\n",
    "                        \"Description\": \"\",  # We'll get descriptions in a separate step\n",
    "                        \"Company\": \"NVIDIA\"\n",
    "                    })\n",
    "                    logger.info(f\"Added job: {title} at {location}\")\n",
    "            \n",
    "        except (StaleElementReferenceException, Exception) as e:\n",
    "            logger.error(f\"Error extracting job details for job {index+1}: {e}\")\n",
    "            continue\n",
    "    \n",
    "    return jobs_data\n",
    "\n",
    "# Improved function to get job descriptions with full page screenshots saved in a separate folder\n",
    "def get_job_descriptions(driver, jobs_data, max_descriptions=100):\n",
    "    \"\"\"\n",
    "    Get job descriptions for a batch of jobs by visiting their individual pages.\n",
    "    Save full page screenshots of each job description in a separate folder.\n",
    "    \"\"\"\n",
    "    logger.info(f\"Getting descriptions for {len(jobs_data)} jobs (up to {max_descriptions})\")\n",
    "    \n",
    "    # Create a dedicated folder for job description screenshots\n",
    "    job_desc_folder = 'job_description_screenshots'\n",
    "    os.makedirs(job_desc_folder, exist_ok=True)\n",
    "    \n",
    "    # Store current URL to return to afterward\n",
    "    original_url = driver.current_url\n",
    "    original_window = driver.current_window_handle\n",
    "    \n",
    "    # Process up to max_descriptions\n",
    "    for i, job in enumerate(jobs_data[:max_descriptions]):\n",
    "        if not job.get(\"Link\"):\n",
    "            continue\n",
    "            \n",
    "        logger.info(f\"Getting description for job {i+1}/{min(len(jobs_data), max_descriptions)}: {job['Title']}\")\n",
    "        \n",
    "        # Create a clean filename from the job title\n",
    "        clean_title = re.sub(r'[\\\\/*?:\"<>|]', \"\", job['Title'])\n",
    "        clean_title = re.sub(r'\\s+', \"_\", clean_title)\n",
    "        clean_title = clean_title[:100] if len(clean_title) > 100 else clean_title\n",
    "        \n",
    "        # Create a new tab for each job\n",
    "        try:\n",
    "            # Open new tab\n",
    "            driver.execute_script(\"window.open('about:blank', '_blank');\")\n",
    "            driver.switch_to.window(driver.window_handles[-1])\n",
    "            \n",
    "            # Navigate to job details page\n",
    "            driver.get(job[\"Link\"])\n",
    "            time.sleep(5)  # Wait for page to load\n",
    "            \n",
    "            # Take a full page screenshot\n",
    "            # First, get the height of the entire page\n",
    "            total_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "            \n",
    "            # Set window size to capture entire page\n",
    "            driver.set_window_size(1920, total_height)\n",
    "            \n",
    "            # Take screenshot and save in the dedicated folder\n",
    "            screenshot_file = f\"{job_desc_folder}/job_{i+1}_{clean_title}.png\"\n",
    "            driver.save_screenshot(screenshot_file)\n",
    "            logger.info(f\"Saved full-page screenshot to {screenshot_file}\")\n",
    "            \n",
    "            # For long pages, also capture screenshots of each section\n",
    "            current_height = 0\n",
    "            viewport_height = 1080\n",
    "            section = 1\n",
    "            \n",
    "            while current_height < total_height:\n",
    "                driver.execute_script(f\"window.scrollTo(0, {current_height});\")\n",
    "                time.sleep(0.5)\n",
    "                section_screenshot = f\"{job_desc_folder}/job_{i+1}_{clean_title}_section_{section}.png\"\n",
    "                driver.save_screenshot(section_screenshot)\n",
    "                current_height += viewport_height\n",
    "                section += 1\n",
    "                \n",
    "            # Reset scroll position\n",
    "            driver.execute_script(\"window.scrollTo(0, 0);\")\n",
    "            \n",
    "            # Extract description using multiple potential selectors\n",
    "            description_selectors = [\n",
    "                \"[data-automation-id='job-description']\",\n",
    "                \".job-description\",\n",
    "                \"#job-description\",\n",
    "                \"[role='main']\",\n",
    "                \"article\",\n",
    "                \"[data-automation-id='jobPosting']\",\n",
    "                \".css-vh281m\",\n",
    "                \".css-1prfaxn\"\n",
    "            ]\n",
    "            \n",
    "            description = \"\"\n",
    "            for selector in description_selectors:\n",
    "                try:\n",
    "                    desc_elements = driver.find_elements(By.CSS_SELECTOR, selector)\n",
    "                    if desc_elements:\n",
    "                        description = desc_elements[0].text.strip()\n",
    "                        if description:\n",
    "                            logger.info(f\"Got description for '{job['Title']}' ({len(description)} chars)\")\n",
    "                            break\n",
    "                except Exception as e:\n",
    "                    logger.debug(f\"Selector {selector} failed: {e}\")\n",
    "            \n",
    "            # Update the job with the description\n",
    "            if description:\n",
    "                job[\"Description\"] = description\n",
    "            \n",
    "            # Close tab\n",
    "            driver.close()\n",
    "            driver.switch_to.window(original_window)\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error getting description for {job['Title']}: {e}\")\n",
    "            # Make sure we're back to the original window\n",
    "            try:\n",
    "                driver.close()\n",
    "                driver.switch_to.window(original_window)\n",
    "            except:\n",
    "                pass\n",
    "    \n",
    "    # Return to original page\n",
    "    try:\n",
    "        driver.get(original_url)\n",
    "        time.sleep(3)\n",
    "    except:\n",
    "        pass\n",
    "        \n",
    "    logger.info(f\"Completed fetching descriptions for {min(len(jobs_data), max_descriptions)} jobs\")\n",
    "    return jobs_data\n",
    "\n",
    "# Function to handle different types of popups\n",
    "def handle_popups(driver):\n",
    "    try:\n",
    "        # Common buttons for accepting cookies, terms, etc.\n",
    "        popup_selectors = [\n",
    "            \"//button[contains(text(), 'Accept')]\", \n",
    "            \"//button[contains(text(), 'I agree')]\",\n",
    "            \"//button[contains(@id, 'accept')]\",\n",
    "            \"//button[contains(@class, 'accept')]\",\n",
    "            \"//button[contains(text(), 'Continue')]\",\n",
    "            \"//button[contains(text(), 'Got it')]\",\n",
    "            \"//button[contains(text(), 'Close')]\",\n",
    "            \"//button[@aria-label='Close']\",\n",
    "            \"//div[contains(@class, 'cookie')]//button\",\n",
    "            \"//div[contains(@id, 'consent')]//button\"\n",
    "        ]\n",
    "        \n",
    "        for xpath in popup_selectors:\n",
    "            try:\n",
    "                buttons = driver.find_elements(By.XPATH, xpath)\n",
    "                for button in buttons:\n",
    "                    if button.is_displayed():\n",
    "                        button.click()\n",
    "                        logger.info(f\"Clicked popup/cookie button with xpath: {xpath}\")\n",
    "                        time.sleep(1)\n",
    "            except Exception:\n",
    "                continue\n",
    "                \n",
    "        # Handle alerts\n",
    "        try:\n",
    "            alert = Alert(driver)\n",
    "            alert.accept()\n",
    "            logger.info(\"Accepted alert popup\")\n",
    "        except:\n",
    "            pass\n",
    "            \n",
    "    except Exception as e:\n",
    "        logger.warning(f\"Error handling popups: {e}\")\n",
    "\n",
    "# Function to validate URL\n",
    "def is_valid_link(url):\n",
    "    if not url or not isinstance(url, str) or not url.startswith(\"http\"):\n",
    "        return False\n",
    "        \n",
    "    # For NVIDIA Workday links, we'll assume they're valid without checking\n",
    "    if \"nvidia.wd5.myworkdayjobs.com\" in url:\n",
    "        return True\n",
    "        \n",
    "    try:\n",
    "        response = requests.head(url, timeout=5, allow_redirects=True)\n",
    "        return response.status_code < 400  # Accept any non-error status\n",
    "    except requests.RequestException:\n",
    "        logger.warning(f\"Invalid link: {url}\")\n",
    "        return False\n",
    "\n",
    "# Improved NVIDIA job scraper function to save all jobs regardless of search keyword\n",
    "def scrape_nvidia_jobs(search_keyword=\"\", max_pages=20, headless=False):\n",
    "    \"\"\"\n",
    "    Scrape NVIDIA jobs with comprehensive approach including pagination.\n",
    "    The search_keyword is used only for searching on the website.\n",
    "    All found jobs will be saved regardless of keyword match.\n",
    "    \n",
    "    Parameters:\n",
    "    search_keyword (str): Keyword to search for (empty string for all jobs)\n",
    "    max_pages (int): Maximum number of pages to scrape\n",
    "    headless (bool): Whether to run in headless mode\n",
    "    \n",
    "    Returns:\n",
    "    list: List of all job dictionaries found\n",
    "    \"\"\"\n",
    "    options = webdriver.ChromeOptions()\n",
    "    \n",
    "    if headless:\n",
    "        options.add_argument('--headless')\n",
    "        \n",
    "    options.add_argument('--disable-gpu')\n",
    "    options.add_argument('--no-sandbox')\n",
    "    options.add_argument('--disable-dev-shm-usage')\n",
    "    options.add_argument('--window-size=1920,1080')\n",
    "    options.add_argument('--user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/98.0.4758.102 Safari/537.36')\n",
    "    \n",
    "    # Create directories for debugging\n",
    "    os.makedirs('screenshots', exist_ok=True)\n",
    "    \n",
    "    driver = None\n",
    "    jobs_data = []\n",
    "\n",
    "    try:\n",
    "        driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=options)\n",
    "        driver.set_page_load_timeout(30)\n",
    "        \n",
    "        # Construct search URL\n",
    "        search_term = search_keyword.replace(\" \", \"%20\") if search_keyword else \"\"\n",
    "        if search_term:\n",
    "            base_url = f\"https://nvidia.wd5.myworkdayjobs.com/en-US/NVIDIAExternalCareerSite?q={search_term}\"\n",
    "        else:\n",
    "            base_url = \"https://nvidia.wd5.myworkdayjobs.com/en-US/NVIDIAExternalCareerSite\"\n",
    "\n",
    "        # Open the NVIDIA careers page\n",
    "        logger.info(f\"Scraping jobs from NVIDIA\" + (f\", searching for '{search_keyword}'\" if search_keyword else \"\"))\n",
    "        driver.get(base_url)\n",
    "        driver.save_screenshot(\"screenshots/nvidia_initial.png\")\n",
    "        \n",
    "        # Handle popups\n",
    "        handle_popups(driver)\n",
    "        \n",
    "        # Wait for results to load - trying different possible selectors\n",
    "        if not wait_for_job_listings(driver, timeout=20):\n",
    "            logger.warning(\"Could not detect job search results loading. Trying manual search...\")\n",
    "            \n",
    "            # Try to search directly by submitting a search form\n",
    "            try:\n",
    "                search_box = driver.find_element(By.CSS_SELECTOR, \"input[type='search'], input[placeholder*='Search']\")\n",
    "                search_box.clear()\n",
    "                search_box.send_keys(search_keyword)\n",
    "                search_box.send_keys(Keys.RETURN)\n",
    "                time.sleep(5)\n",
    "                logger.info(\"Tried manual search submission\")\n",
    "                driver.save_screenshot(\"screenshots/nvidia_manual_search.png\")\n",
    "                \n",
    "                # Wait again for results\n",
    "                wait_for_job_listings(driver, timeout=15)\n",
    "            except Exception as e:\n",
    "                logger.error(f\"Manual search also failed: {e}\")\n",
    "        \n",
    "        # Scroll to load all results on first page\n",
    "        job_count = scroll_to_load_all(driver, max_scrolls=20, wait_time=3)\n",
    "        driver.save_screenshot(\"screenshots/nvidia_after_scroll.png\")\n",
    "        \n",
    "        # Handle pagination and collect all jobs\n",
    "        all_jobs = handle_pagination(driver, max_pages=max_pages)\n",
    "        logger.info(f\"Collected {len(all_jobs)} total jobs after pagination\")\n",
    "        \n",
    "        # Get job descriptions for all collected jobs\n",
    "        jobs_with_descriptions = get_job_descriptions(driver, all_jobs, max_descriptions=200)\n",
    "        \n",
    "        # Save all jobs regardless of search keyword\n",
    "        jobs_data = jobs_with_descriptions\n",
    "        logger.info(f\"Saving all {len(jobs_data)} jobs found in search results\")\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error during scraping from NVIDIA: {e}\")\n",
    "        if driver:\n",
    "            driver.save_screenshot(\"screenshots/nvidia_error.png\")\n",
    "\n",
    "    finally:\n",
    "        if driver:\n",
    "            driver.quit()\n",
    "\n",
    "    return jobs_data\n",
    "\n",
    "# Main function to scrape and save results to CSV\n",
    "def main(search_keyword=\"\", max_pages=20, headless=False):\n",
    "    start_time = time.time()\n",
    "    logger.info(f\"Starting NVIDIA job scraper at {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "    \n",
    "    # Create screenshots directory\n",
    "    os.makedirs('screenshots', exist_ok=True)\n",
    "    \n",
    "    # Create job description screenshots directory\n",
    "    os.makedirs('job_description_screenshots', exist_ok=True)\n",
    "    \n",
    "    # Scrape NVIDIA jobs\n",
    "    jobs_data = scrape_nvidia_jobs(search_keyword, max_pages, headless)\n",
    "    \n",
    "    # Generate filenames with timestamps\n",
    "    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "    keyword_slug = search_keyword.replace(' ', '_') if search_keyword else 'all'\n",
    "    detailed_filename = f\"nvidia_jobs_detailed_{keyword_slug}_{timestamp}.csv\"\n",
    "    simple_filename = f\"nvidia_jobs_simple_{keyword_slug}_{timestamp}.csv\"\n",
    "    \n",
    "    # Save results\n",
    "    if jobs_data:\n",
    "        # Create DataFrame\n",
    "        df = pd.DataFrame(jobs_data)\n",
    "        \n",
    "        # Save detailed CSV with descriptions\n",
    "        df.to_csv(detailed_filename, index=False, encoding='utf-8-sig')\n",
    "        logger.info(f\"Detailed jobs saved to '{detailed_filename}'\")\n",
    "        \n",
    "        # Create and save a simplified CSV without descriptions\n",
    "        simple_df = df[['Title', 'Location', 'Link']].copy()\n",
    "        simple_df.to_csv(simple_filename, index=False, encoding='utf-8-sig')\n",
    "        logger.info(f\"Simplified jobs list saved to '{simple_filename}'\")\n",
    "        \n",
    "        # Also create a filtered file if a search keyword was provided\n",
    "        if search_keyword:\n",
    "            filtered_df = df[df['Title'].str.contains(search_keyword, case=False)].copy()\n",
    "            filtered_filename = f\"nvidia_jobs_filtered_{keyword_slug}_{timestamp}.csv\"\n",
    "            filtered_df.to_csv(filtered_filename, index=False, encoding='utf-8-sig')\n",
    "            logger.info(f\"Jobs filtered by keyword '{search_keyword}' saved to '{filtered_filename}'\")\n",
    "            logger.info(f\"Found {len(filtered_df)} jobs matching the keyword out of {len(df)} total jobs\")\n",
    "        \n",
    "        # Print summary\n",
    "        print(\"\\n\" + \"=\"*50)\n",
    "        print(f\"NVIDIA Job Scraping Results:\")\n",
    "        print(f\"Total jobs found: {len(df)}\")\n",
    "        print(f\"Unique locations: {len(df['Location'].unique())}\")\n",
    "        print(f\"Sample jobs:\")\n",
    "        print(df[['Title', 'Location']].head())\n",
    "        print(\"\\nTop locations:\")\n",
    "        print(df['Location'].value_counts().head())\n",
    "        print(f\"\\nResults saved to:\")\n",
    "        print(f\"- {detailed_filename}\")\n",
    "        print(f\"- {simple_filename}\")\n",
    "        if search_keyword:\n",
    "            print(f\"- {filtered_filename}\")\n",
    "        print(\"=\"*50)\n",
    "        \n",
    "        elapsed_time = time.time() - start_time\n",
    "        logger.info(f\"Completed in {elapsed_time:.2f} seconds\")\n",
    "        \n",
    "        return df\n",
    "    else:\n",
    "        logger.warning(f\"No jobs found with search keyword '{search_keyword}'\")\n",
    "        print(\"\\nNo jobs found to display.\")\n",
    "        \n",
    "        elapsed_time = time.time() - start_time\n",
    "        logger.info(f\"Process completed with no results in {elapsed_time:.2f} seconds\")\n",
    "        \n",
    "        return pd.DataFrame()\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"NVIDIA Job Scraper\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    # Get user input\n",
    "    job_title = input(\"Enter job title to search for (leave empty to get all jobs): \").strip()\n",
    "    \n",
    "    try:\n",
    "        max_pages = int(input(\"Maximum number of pages to scrape (default 20): \") or \"20\")\n",
    "    except ValueError:\n",
    "        max_pages = 20\n",
    "        print(\"Invalid input. Using default of 20 pages.\")\n",
    "    \n",
    "    headless_mode = input(\"Run in headless mode? (y/n, default: n): \").strip().lower() == 'y'\n",
    "    \n",
    "    print(\"\\nStarting job scraper...\")\n",
    "    print(\"This may take several minutes depending on the number of jobs and pages.\")\n",
    "    print(\"Progress will be logged to the console and a log file.\")\n",
    "    \n",
    "    # Run the scraper\n",
    "    main(job_title, max_pages, headless_mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1530967-e642-48f7-a9c6-907ff991aa3b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
